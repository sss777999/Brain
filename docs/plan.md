MEMORY MODEL â€” SPECIFICATION AND IMPLEMENTATION STATUS

========================================
ROADMAP: BRAIN â€” BIOLOGICALLY PLAUSIBLE MEMORY MODEL
========================================

PRINCIPLE: Everything as in the real brain. No artificial constructs.

========================================
AUTHORITATIVE ROADMAP (v2026-01-23)
========================================

This document contains both historical implementation notes and a forward-looking roadmap.
This section is the single source of truth for "what to do next".

STATUS (verified 2026-01-27):
- CURRICULUM: 49/50 (98.0%)
- STRICT: 3/3 (100%)
- PRESCHOOL: 46/48 (95.8%)
- GRADE1: 64/64 (100%)
- FineWeb-Edu: 7/9 (77.8%)
- PARAPHRASE: 25/50 (50.0%) â€” surface form robustness tests
- bAbI Task 1: 250/250 (100%)
- TOTAL: 444/474 (93.7%) all tests including bAbI + paraphrase

BASELINE COMPARISON (verified 2026-01-27):
All baselines trained on identical data (curriculum.py sentences).
- Brain average: 88.8%
- TF-IDF average: 27.3%
- BM25 average: 25.7%
- Brain advantage: +61.5% vs TF-IDF, +63.1% vs BM25
- bAbI: 100% vs 0% (TF-IDF/BM25 cannot handle working memory)

TRAINING PIPELINE (January 2026):
CURRICULUM â†’ PRESCHOOL â†’ GRADE1 â†’ FineWeb-Edu
(Note: bAbI is used for TESTING working memory, not training)
All stages use source="LEARNING" for proper SOURCE MEMORY tagging.

========================================
KNOWN ISSUES â€” REQUIRE ARCHITECTURAL SOLUTIONS
========================================

The following 9 PRESCHOOL tests fail and require NEW biological mechanisms (not data fixes):

1. HOMONYM DISAMBIGUATION (Context-dependent word sense)
   Problem: "What comes after A?" â€” letter "A" conflicts with article "a"
   Biology: Humans disambiguate via context (alphabet context â†’ letter sense)
   Solution needed: Context-gated lexical access (different neurons for different senses)
   Affects: "What comes after A?", "What is the first letter?"

2. LOGICAL INFERENCE FOR YES/NO QUESTIONS
   Problem: "Is a turtle faster than a rabbit?" expects "no", model returns factual comparison
   Biology: Prefrontal cortex evaluates propositions and generates yes/no judgments
   Solution needed: PFC evaluation circuit for boolean questions
   Affects: "Is a turtle faster than a rabbit?", "Is a feather heavier than a rock?"

3. DOMAIN-SPECIFIC MEMORY PRIORITIZATION
   Problem: "What happens when you touch fire?" returns FineWeb garbage instead of preschool answer
   Biology: Episodic memories have source tags, PFC gates retrieval by relevance
   Solution needed: Source tagging during encoding + top-down filtering during retrieval
   Affects: "What happens when...", "What is the opposite of in?"

4. TEMPORAL SEQUENCE RETRIEVAL
   Problem: "What comes after ten?" fails despite correct data
   Biology: Hippocampal time cells encode sequence position
   Solution needed: Strengthen temporal connector mechanism in pattern_complete
   Affects: "What comes after ten?"

NON-REGRESSION CONTRACT (hard gate for every next phase):
- Keep 376/376 passing.
- Add deterministic tests for each new capability (sequence/word order, compositional reasoning).

INTELLIGENCE PRIORITIES (no learnable operators for now):
- Word order / sequence control:
  - (A) Correct token order in recalled episodes and generated answers.
  - (B) Correct ordering constraints inside patterns/attractors (sequence is not a set).
- Text understanding:
  - Compositionality (relations/roles/bindings).
  - Multi-step retrieval/reasoning using PFC as a scratchpad.

NEXT PHASES (recommended order):
1) PHASE 3: API boundaries (Lexicon/InputLayer + OutputLayer) â€” âœ… DONE (January 2026)
2) PHASE 3.6: Motor Output / Sequence Generator â€” âœ… DONE (January 2026)
3) PHASE 3.7: Compositional WM reasoning â€” âœ… DONE (January 2026)
4) PHASE 3.8: SOURCE MEMORY â€” âœ… DONE (January 2026)
5) PHASE 4: Basal Ganglia (BG integration into ask()) â€” âœ… DONE (January 2026)
6) PHASE 5: Neuromodulator Expansion (ACh/NE/5-HT) â€” âœ… DONE (January 2026)
7) PHASE 7: Internal Actions (BG-driven cognitive control) â€” âœ… DONE (January 2026)
8) PHASE 6: TRUE REPLAY / SWR (temporal compression) â€” âœ… DONE (January 2026)
9) NMDA Receptor Mechanism (dynamic threshold for context attention) â€” âœ… DONE (January 2026)
10) Cross-Episode Linking (semantic links via shared context during REM) â€” âœ… DONE (January 2026)
11) Baseline Comparison (TF-IDF/BM25) â€” âœ… DONE (January 2026)
12) Semantic Roles Integration â€” âœ… DONE (January 2026)
    - Event Schemas: Episode stores predicate + 18 role types (agent, patient, theme, location, etc.)
    - Goal-conditioned Retrieval: PFC infers expected roles from question type ("What is X?" â†’ category)
    - Role bonus in CA3 scoring for episodes with matching semantic roles
    - Biology: Fillmore's Case Grammar, temporal-parietal cortex (Binder 2009)

13) Baselines â€” âœ… DONE (February 2026)
    - TF-IDF: term frequency-inverse document frequency
    - BM25: probabilistic IR model (Robertson et al.)
    - MemNet: attention over memory slots (Weston et al. 2015)
    - NTM: external memory with content-based addressing (Graves et al. 2014)
    - All baselines tested on identical curriculum data

BASELINE SUMMARY:
| Baseline    | Type                  | Working Memory | Source Memory | Bio-plausible |
|-------------|-----------------------|----------------|---------------|---------------|
| TF-IDF      | IR (term frequency)   | No             | No            | No            |
| BM25        | IR (probabilistic)    | No             | No            | No            |
| MemNet      | Attention over memory | Yes            | No            | No            |
| NTM         | External memory       | Yes            | No            | No            |
| **Brain**   | Hippocampal circuit   | Yes            | Yes           | Yes           |

QA Baselines (TF-IDF, BM25): tested on all QA tests
Working Memory Baselines (MemNet, NTM): tested ONLY on bAbI Task 1

14) bAbI Tasks 2-20 â€” ðŸ”„ TODO (Future)
    Currently only Task 1 (single supporting fact) is tested.
    Tasks 2-20 test KEY cognitive abilities that Brain should support:
    - Task 2: Two supporting facts
    - Task 3: Three supporting facts  
    - Task 4: Two argument relations
    - Task 5: Three argument relations
    - Task 6: Yes/No questions
    - Task 7: Counting
    - Task 8: Lists/Sets
    - Task 9: Simple negation
    - Task 10: Indefinite knowledge
    - Task 11: Basic coreference
    - Task 12: Conjunction
    - Task 13: Compound coreference
    - Task 14: Time reasoning
    - Task 15: Basic deduction
    - Task 16: Basic induction
    - Task 17: Positional reasoning
    - Task 18: Size reasoning
    - Task 19: Path finding
    - Task 20: Agent's motivations
    These are CRITICAL for demonstrating Brain's reasoning capabilities.

The goal is NOT to beat all baselines, but to show unique capabilities:
  - Working memory (bAbI): TF-IDF/BM25 = 0%, MemNet/NTM/Brain > 0%
  - Source memory: trust-weighted retrieval (only Brain)
  - Biological plausibility: mechanisms with neuroscience references

========================================
PHASE 3.8: SOURCE MEMORY [âœ… DONE â€” January 2026]
========================================

PROBLEM:
When multiple knowledge sources are trained (CURRICULUM, PRESCHOOL, GRADE1, FINEWEB),
new knowledge interferes with existing knowledge (retroactive interference).
Example: "What is ice?" returns PRESCHOOL data instead of CURRICULUM answer.

BIOLOGY:
The hippocampus stores not only WHAT was learned, but also WHERE/WHEN/HOW:
- "I learned this in school" (institutional source)
- "Mom told me this" (personal source)  
- "I read this in a book" (media source)
This is called SOURCE MEMORY (Johnson et al., 1993).

Over time, source details fade but the knowledge remains (semantic consolidation).
We remember facts from school but forget which class, which day, which teacher.

IMPLEMENTATION:
1. Each episode gets a source tag during encoding:
   episode.source = "LEARNING" | "EXPERIENCE" | "CONVERSATION" | "MEDIA" | "working_memory"
   â†’ Implemented in episode.py (Episode.__init__)

2. Episodes also get a reliability/trust score:
   - "LEARNING" (explicit teaching) â†’ trust=1.0
   - "EXPERIENCE" (personal experience) â†’ trust=0.9
   - "CONVERSATION" (overheard) â†’ trust=0.7
   - "MEDIA" (internet) â†’ trust=0.5
   â†’ Implemented in episode.py (_get_trust_for_source) + config.py (SOURCE_TRUST)

3. During retrieval, PFC applies top-down filtering:
   - QuestionType classification â†’ preferred source TYPES
   - SEMANTIC_FACT ("What is X?") â†’ LEARNING, EXPERIENCE
   - EXPERIENCE ("What happens when X?") â†’ LEARNING, EXPERIENCE, CONVERSATION
   - LOCATION ("Where is X?") â†’ WORKING_MEMORY, CONVERSATION, LEARNING
   â†’ Implemented in pfc.py (classify_question, get_preferred_sources)
   â†’ Config in config.py (QUESTION_TYPE_SOURCES)

4. Trust-weighted scoring in CA3:
   - score = base_score * trust_multiplier
   - LEARNING (trust=1.0) beats MEDIA (trust=0.5) for same overlap
   â†’ Implemented in ca3.py (_score_episodes)

5. Consolidation gradually loses source specificity:
   - [TODO] Not yet implemented â€” source remains static

REFERENCE:
Johnson, M.K., Hashtroudi, S., & Lindsay, D.S. (1993). "Source monitoring."
Psychological Bulletin, 114(1), 3-28. DOI: 10.1037/0033-2909.114.1.3

This solves KNOWN ISSUES #3 (Domain-specific memory prioritization).

LEGACY PHASE MAPPING (kept for traceability; do not delete):
- "PHASE 6: GENERATOR" (legacy section below) == PHASE 3.6 in this roadmap.
- "PHASE 5.5/5.6" (working memory + temporal retrieval) are implemented milestones.
- The remediation block "BIOLOGICAL PLAUSIBILITY REMEDIATION PLAN" is historical context for completed PHASE 0..2 items.
- Old "PHASE 3: Basal Ganglia" is now PHASE 4; old "PHASE 4: API" is now PHASE 3.

PHASE 1: SEMANTIC MEMORY [âœ… DONE]
- Connections between concepts via Hebbian learning
- Myelination of frequent paths (STDP)
- Spreading activation
- Chunking as emergent property
- Dual Stream: SEMANTIC (ventral) + SYNTACTIC (dorsal)

PHASE 2: EMERGENT HIERARCHY [âœ… DONE]
- NO explicit IS_A/HAS_PROPERTY links â€” not biologically plausible
- Categories arise EMERGENTLY from connection structure
- Nodes with many incoming SEMANTIC connections = categories
- find_categories() â€” category discovery from graph topology
- get_related_concepts() â€” related concepts by connection strength

PHASE 2.5: BIOLOGICAL ATTENTION [âœ… DONE]
- generate_with_attention() â€” generation with context
- CUMULATIVE CONTEXT: each word adds neighbors
- DECAY: old activations fade (as in the brain)
- HUB PENALTY: hubs (common words) receive less activation
  â€” like high threshold for neurons with many inputs
- SEED ANCHORING: topic (seed) always remains in memory
- DEAD-END HANDLING: if no candidates â€” search from active words
- Working memory: limited capacity (~7 items)

PHASE 3: EPISODIC MEMORY [âœ… DONE]
Biological basis (Hippocampal Memory Indexing Theory, Teyler & Discenna):
- Hippocampus = INDEX, not data storage
- Three subregions:
  - DG (Dentate Gyrus) â€” pattern separation (sparse coding, ~2% neurons, Rolls et al. 2007)
  - CA3 â€” pattern completion (recurrent network, restoration from partial cue)
  - CA1 â€” output to cortex
- Episode â€” episodic trace (index + context + reference to pattern)
- Sharp Wave-Ripples (SWR) â€” replay during sleep/rest for consolidation
- Consolidation: hippocampus â†’ cortex (episodic â†’ semantic memory)

CA3 ATTRACTOR DYNAMICS:
- Pattern completion uses 5 iterations (gamma cycles)
- REFERENCE: Rolls, E.T. (2013). "The mechanisms for pattern completion and 
  pattern separation in the hippocampus." Frontiers in Systems Neuroscience, 7:74.
  DOI: 10.3389/fnsys.2013.00074
- Key findings:
  - Recall in hippocampus completes in 100-200ms (empirical data)
  - Gamma rhythm: 30-80Hz, each cycle ~15-30ms
  - 3-5 gamma cycles = 100-200ms = pattern completion time
  - Recurrent CA3 collaterals spread activation ~1 synaptic hop per cycle

PHASE 3.7: BIOLOGICAL EFFICIENCY MECHANISMS [âœ… DONE]
December 2025

1. DILUTED CONNECTIVITY (Rolls et al., 2007)
   - HEBBIAN_WINDOW_SIZE = 4 (was 8)
   - Brain is NOT fully connected â€” connections only between nearby neurons
   - Result: 4x training speedup

2. HETEROSYNAPTIC LTD (Long-Term Depression)
   - When one connection strengthens, neighbors weaken
   - Applied during sleep_consolidation()
   - Maintains sparse coding and prevents saturation

3. SYNAPTIC SCALING (Turrigiano, 2008)
   - Homeostatic plasticity
   - Neurons maintain stable activity level
   - Overactive neurons â€” their connections weaken
   - Inactive neurons â€” their connections strengthen

4. COMPETITIVE LEARNING / WINNER-TAKE-ALL in DG
   - Experienced neurons (with MYELINATED connections) win competition
   - Lateral inhibition suppresses weak competitors
   - pattern_separate() considers neuron experience

5. PREDICTIVE CODING (Rao & Ballard, 1999)
   - Brain transmits only PREDICTION ERRORS
   - MYELINATED connections = predictable, not additionally strengthened
   - Weak connections = unexpected, fully strengthened
   - Saves energy and speeds up learning new information

PHASE 3.5: ATTENTION AT RETRIEVAL [âœ… DONE]
Same mechanisms work BOTH during learning AND during inference:
- **Question context (query_words)** is maintained during pattern_complete
- **query_overlap** â€” priority for episodes with original question words
- **avg_strength** â€” average connection strength queryâ†’answer (not sum!)
  - Normalized by number of words in episode
  - Myelinated connections (MYELINATED) have greater weight
  - forward_usage is considered (attention during learning strengthens connections)
- **Activation history** â€” FULL spreading activation history is used
  - Working Memory Limit constrains final state
  - But for retrieval all activated neurons are needed
- Score formula: query_overlap * 50000 + avg_strength * 100 + overlap
- **Lateral Inhibition** â€” query words don't receive bonus (self-inhibition)

PHASE 3.6: INTERROGATIVE WORDS + LLM POSTPROCESS [âœ… DONE]
December 2025

1. INTERROGATIVE_WORDS â€” separate class (what, where, who, when, why, how, which)
   - Create neurons (have semantic content)
   - Participate in spreading activation during ask()
   - Do NOT create connections between themselves (like function words during learning)
   - BIOLOGY: Activate "expectation template" in prefrontal cortex

2. NO connector normalization â€” biologically plausible!
   - Brain stores SPECIFIC word forms, not abstract lemmas
   - "is", "was", "are" stored AS IS
   - Only articles (a, an, the) removed from compound connectors

3. Temperature â€” probabilistic episode selection
   - temperature=0: greedy (deterministic, always top-1)
   - temperature>0: softmax-like sampling
   - BIOLOGY: Stochasticity in synaptic transmission

4. config.py â€” unified config for all model parameters
   - All constants in one place
   - Easy to change parameters without code search

5. LLM Postprocess (llm_postprocess.py) â€” Broca's area
   - Brain outputs semantics: "dog is animal"
   - LLM (Qwen2.5:3b via Ollama) formats into speech: "A dog is an animal."
   - LLM **does NOT change facts**, only grammar
   - BIOLOGY: Broca's area transforms semantics into grammatically correct speech

RESULT: CURRICULUM 49/50 (98%), GRADE1 64/64 (100%), FineWeb-Edu 7/9 (77.8%)

PHASE 3.8: HIPPOCAMPAL TIME CELLS [âœ… DONE]
December 2025

1. **input_words: Tuple** â€” episodes preserve word order
   - Hippocampus encodes ORDER of events via time cells
   - During recall, words activate in the order they were encoded
   - BIOLOGY: Time cells in hippocampus encode temporal sequence

2. **generate_answer_from_episode** uses order from episode
   - With equal connection priority, word is chosen by order in episode
   - Fallback: remaining words added in order from episode

3. **Serialization/deserialization** preserves word order
   - save_model_numpy() saves input_words
   - load_model_numpy() restores input_words

PHASE 3.9: SLEEP CONSOLIDATION [âœ… DONE]
January 2026

1. **SWR Replay with connection strengthening**
   - `sleep()` accepts `word_to_neuron` for connection access
   - `_replay_episode()` â€” LTP during replay (forward_usage += 1)
   - Recency bias â€” recent episodes replay more often
   - BIOLOGY: Sharp Wave-Ripples reproduce neuron sequences

2. **Consolidation with myelination**
   - `_consolidate()` â€” episode connections â†’ MYELINATED
   - Episode becomes part of semantic memory
   - BIOLOGY: Active Systems Consolidation (Born & Wilhelm 2012)

3. **bAbI for TESTING (not training), using only pfc (prefrontal cortex)**
   - bAbI tests working memory without task-specific training
   - Model learns general WM mechanisms from curriculum/preschool/grade1
   - bAbI Task 1: 250/250 (100%) validates WM functionality

RESULT (verified 23.01.2026): CURRICULUM 49/50 (98%), GRADE1 64/64 (100%), FineWeb-Edu 7/9 (77.8%), bAbI Task 1: 250/250 (100%)

========================================
PHASE 0: PlasticityMode (LEARN vs INFER) [âœ… DONE â€” January 2026]
========================================

BIOLOGY: Brain distinguishes learning and inference modes.
When answering a question, LTM should not be modified.

IMPLEMENTATION:
- PlasticityMode enum in config.py: LEARN / INFER
- Helpers: is_learning_mode(), is_inference_mode(), set_learning_mode(), set_inference_mode()
- ask() automatically switches to INFER and restores LEARN after
- Guards in plasticity paths:
  - mark_used_forward(), mark_used_backward()
  - apply_stdp(), apply_stdp_with_timing()
  - consolidate_eligibility()

TEST [INFER-NO-LEARN]: 0 LTM changes after ask() (1,249,260 connections verified)

========================================
PHASE 1: STDP/HH INTEGRATION [âœ… DONE â€” January 2026]
========================================

BIOLOGY: Spike-timing dependent plasticity based on spike timing.

IMPLEMENTATION:
- SpikingMode enum: RATE_BASED / LIF / HH
- _simulate_spike_pair() calls STDP during learning
- apply_stdp_with_timing(pre_time, post_time) in connection.py
- accumulated_stdp_strength for state transitions via _update_state_stdp()
- STDP parameters in config: A_PLUS, A_MINUS, TAU_PLUS, TAU_MINUS, thresholds

========================================
PHASE 1b: THREE-FACTOR LEARNING [âœ… DONE â€” January 2026]
========================================

BIOLOGY (Gerstner 2018): STDP â†’ eligibility â†’ DA Ã— eligibility = Î”weight

IMPLEMENTATION:
- apply_stdp_with_timing() updates eligibility, does NOT immediately change state
- Novelty â†’ release dopamine (already implemented)
- consolidate_eligibility(dopamine, time) converts traces to changes
- _simulate_spike_pair() calls consolidate_eligibility() with current DA
- EligibilityTrace.decay() in spiking.py

========================================
PHASE 2: CA3 ATTRACTOR DYNAMICS [âœ… DONE â€” January 2026]
========================================

BIOLOGY (Rolls 2013): CA3 = SHARED recurrent network with recurrent collaterals.
Pattern completion via iterative dynamics, NOT argmax over episode list.

IMPLEMENTATION (ca3.py â€” NEW MODULE):
- CA3 class with iterative attractor dynamics
- pattern_complete() â€” iterative spreading + WTA + stability check
- _spread_recurrent() â€” activation via recurrent connections
  - MYELINATED: strength=0.8, USED: 0.4, NEW: 0.1
  - TOP-DOWN: connector match â†’ strength *= 5.0
- _apply_inhibition() â€” lateral inhibition (Winner-Take-All, top-K=20)
- _score_episodes() â€” full scoring logic:
  - Query overlap filtering
  - Connection strength with context multiplier (context words Ã— 3.0)
  - 2-hop paths (CA3 recurrent collaterals)
  - Context diversity bonus (Spens & Burgess 2024)
  - Connector matching (multiplicative enhancement/suppression)
  - Unconnected context filtering (anti-hallucination)
  - Recency bias for working_memory (Howard & Kahana 2002)
  - Consolidation bonuses
  - Divisive normalization (Carandini & Heeger 2012)

INTEGRATION:
- RETRIEVAL_MODE in config.py: "HEURISTIC" (legacy) or "CA3" (default)
- Hippocampus._ca3 â€” explicit dependency (not singleton)
- pattern_complete_attractor() â€” inverted index + VERB_FORMS expansion
- PFC task-set cues: `PFC.get_binding_tokens()` provides content-only cues for CA3 scoring and hippocampal binding checks (fallback: raw `query_ids` if empty).
- Structural connector gating: `query_connector` is set only for the main interrogative schema (avoids subordinate clauses like "... when it is cold").
- Connector specificity: connector prefix matching is restricted to true connector families (currently only `with_*`) to avoid accidental `is`â†’`is_a` matches.
- Confidence threshold â€” "I do not know" filter

RESULT (verified 23.01.2026): 419/424 tests (98.8%), CURRICULUM 49/50 (98%), STRICT 3/3 (100%), bAbI Task 1 250/250 (100%), FineWeb-Edu 7/9 (77.8%)

========================================

PHASE 3.10: SEMANTIC INFERENCE [ðŸ”´ TODO]

1. **Regression "What is an apple?"** [âœ… SOLVED]
   - Problem: bAbI episode beat curriculum due to high forward_usage
   - Solution: Top-Down Modulation (Zanto 2011, Desimone & Duncan 1995)
     - Multiplicative, NOT additive: relevant *5.0, irrelevant *0.2
     - Applied to forward AND backward connections

2. **bAbI: went_to = is_in**
   - Problem: model doesn't understand that motion verb = result
   - Solution: verb frames for motion verbs

3. **Temporal recency**
   - Problem: returns first fact, not last
   - Solution: recency bias in pattern_complete

PHASE 4: WORKING MEMORY AND ATTENTION [PRIORITY - foundation for reasoning]
- BIOLOGY: No PFC = no reasoning â€” nowhere to store intermediate results
- Prefrontal cortex as buffer for active patterns
- Limited capacity (~7 items) via inhibition
- Attention gating: top-down filtering by goal relevance
- Manipulation via reactivation and pattern combination
- IMPLEMENTATION: pfc.py [âœ… FULL VERSION]
  - PFC: buffer ~7 slots, decay, gating
  - AttentionGate: top-down modulation
  - SourceType: LEARNING/PAPA/OTHER
  - MemoryRouter: routing by source + contradiction check
  - ThinkingEngine: emergent reasoning via spontaneous activation

PHASE 4.1: INFORMATION PROCESSING MODES
========================================

3 INFORMATION SOURCES:

1. LEARNING (Knowledge)
   - Source: books, facts, textbook
   - Interface: train.py / learn()
   - Destination: Hippocampus â†’ Cortex (long-term)
   - Trust: full (like child in school)
   - Already works via current train.py

2. PAPA (Creator)
   - Source: system creator (separate CLI)
   - Interface: papa_cli.py [âœ… IMPLEMENTED]
   - Destination: long-term (info about and from papa)
   - Feature: can update knowledge on contradiction
   - On contradiction: DIALOG "I have X, you say Y. What's correct?"
   - Papa's answer â†’ update/keep/supplement knowledge

3. OTHER (Others)
   - Source: bAbI, random people, stories
   - Interface: context() in train.py [âœ… IMPLEMENTED]
   - Destination: PFC â†’ decay
   - On contradiction with knowledge: do NOT absorb

4. THINKING (Reasoning) â€” emergent
   - Trigger: spontaneous activation (noise in neurons)
   - Condition: activation chain > threshold (determined by network)
   - Mechanism: when network is dense enough (many MYELINATED),
     random activation produces chain â†’ this is a thought
   - NOT hardcoded: threshold = average chain length in current network

IMPORTANCE (emergent, no hardcoding):
- hub_score = number of MYELINATED connections
- context_diversity = repetition from different sources
- Real usage strengthens connections

CONTRADICTION CHECK:
- New information compared with existing knowledge
- Contradiction â†’ conflict â†’ dialog (for papa) or rejection (for others)

PHASE 5: CAUSALITY AND REASONING [âœ… IMPLEMENTED]
- IMPLEMENTATION: pfc.py, train.py
  - ThinkingEngine: emergent reasoning via spontaneous activation
  - InferenceEngine: inference via network connections (NOT hardcoded!)
- Temporal sequence: A â†’ B (A was before B)
- Connection directionality already exists (forward_usage vs backward_usage)
- Causality = strong directed connection + temporal pattern
- NO explicit CAUSES/ENABLES types â€” this is emergent
- Inference via TEMPORARY EPISODES [âœ… WORKS 100% bAbI]
  - context("John went to garden") â†’ temporary episode in Hippocampus
  - ask("Where is John?") â†’ pattern_complete with recency bias
  - clear_context() â†’ cleanup of temporary episodes/connections

PHASE 5.5: WORKING MEMORY (PFC) [âœ… IMPLEMENTED]
January 2026

BIOLOGY (Miller & Cohen 2001, Baddeley 2000):
- Prefrontal Cortex holds TEMPORARY information
- Working memory â‰  long-term memory
- Capacity ~7Â±2 items (Miller's Law)
- Decay/interference on context switch

IMPLEMENTATION:
1. TEMPORARY CONNECTIONS (train.py context())
   - On "hearing" a phrase, TEMPORARY connections between words are created
   - Connections exist while context is active
   - clear_context() removes them (like working memory forgetting)

2. TEMPORARY EPISODES (train.py context())  
   - Facts recorded as episodes with source="working_memory"
   - Inverted index updated (otherwise pattern_complete won't find)
   - Removed on clear_context()

3. RECENCY BIAS (hippocampus.py pattern_complete())
   - Working memory episodes get recency_bonus = w1 * 2
   - Later facts in session get + timestamp * 1000
   - BIOLOGY: Howard & Kahana 2002 - temporal context model

4. PFC SLOTS (pfc.py)
   - Tuple instead of Set (preserves word order - time cells)
   - GOAL slot for current task
   - CONTEXT slots for facts
   - Capacity limit via competition

RESULTS:
- bAbI Task 1: 100% (was 45% with hardcode, 21% without)
- Main tests: 376/376 (100.0%) â€” verified 13.01.2026 (legacy milestone: 124/126 (98.4%))
- No hardcoding like "if word == 'to'" or common_words lists

PHASE 5.6: TEMPORAL RETRIEVAL REFINEMENT [âœ… IMPLEMENTED]
January 2026

BIOLOGY (Temporal Context Model, Howard & Kahana 2002):
- "Where is X?" â†’ search CURRENT state â†’ recency bias
- "Where was X?" â†’ search PAST state â†’ reverse recency

IMPLEMENTATION:
1. TENSE DETECTION in hippocampus.py pattern_complete():
   - PAST_MARKERS: was, were, went, had, did, before, earlier, moved, journeyed
   - PRESENT_MARKERS: is, are, am, now, currently
   - query_has_past + NOT query_has_present â†’ reverse recency
   - Otherwise â†’ standard recency bias

2. VERB_FORMS as "language genome":
   - Morphological verb forms (go/goes/went, move/moved/moving)
   - Biologically grounded: like Chomsky's Universal Grammar
   - Part of "innate" language structures

3. SKIP_FOR_UNCONNECTED includes tense markers:
   - is, are, am, was, were, be, been
   - Tense markers determine question TIME, not content
   - Otherwise "is" would block matching with episodes without "is"

RESULT: bAbI Task 1: 88% â†’ 100%


# BIOLOGICAL PLAUSIBILITY REMEDIATION PLAN (after rigorous audit)

---
## âœ… PHASE 1: STDP/HH INTEGRATION INTO LEARNING (CRITICAL) â€” COMPLETED 09.01.2026
**Status:** 376/376 tests (100.0%) â€” verified 13.01.2026

### Implemented:
- [x] **1.2.1** `SpikingMode` enum in config.py: `RATE_BASED` / `LIF` / `HH`
- [x] **1.2.2** `_simulate_spike_pair()` calls STDP during learning
- [x] **1.2.3** `apply_stdp_with_timing(pre_time, post_time)` in connection.py
- [x] **1.2.4** `accumulated_stdp_strength` for state transitions via `_update_state_stdp()`
- [x] **1.2.5** STDP parameters in config: A_PLUS, A_MINUS, TAU_PLUS, TAU_MINUS, thresholds

### Files changed:
- `config.py` â€” SpikingMode enum, STDP parameters
- `connection.py` â€” accumulated_stdp_strength, apply_stdp_with_timing(), _update_state_stdp()
- `train.py` â€” _simulate_spike_pair() uses STDP in LIF/HH mode

---
## âœ… PHASE 0: PlasticityMode (LEARN vs INFER) [âœ… DONE â€” 09.01.2026]
**Status:** Implemented

### Implemented:
- [x] **0.2.1** `PlasticityMode` enum in config.py: `LEARN` / `INFER`
- [x] **0.2.2** Helper functions: `is_learning_mode()`, `is_inference_mode()`, `set_learning_mode()`, `set_inference_mode()`
- [x] **0.2.3** `ask()` automatically switches to INFER mode and restores LEARN after
- [x] **0.2.4** `mark_used_forward()` and `apply_stdp_with_timing()` check mode

### Files changed:
- `config.py` â€” PlasticityMode enum, helper functions
- `connection.py` â€” mode check in plasticity methods
- `train.py` â€” ask() uses try/finally for INFER mode

### LTM vs short-term state boundary clarification:
- **Allowed in INFER:** changing short-term states (STP, membrane variables, spike queues)
- **Forbidden in INFER:** changing LTM (forward_usage, backward_usage, ConnectionState, consolidation)

### âœ… Test [INFER-NO-LEARN] â€” COMPLETED 09.01.2026
- [x] Serialize connection state before/after ask()
- [x] Verify LTM parameters unchanged
- [x] Result: **0 LTM changes** (1,249,260 connections verified)

### Additionally protected methods:
- [x] `mark_used()` â€” guard added
- [x] `mark_used_backward()` â€” guard added
- [x] `consolidate_eligibility()` â€” guard added

---
## âœ… PHASE 1b: THREE-FACTOR AS BASE PROTOCOL â€” COMPLETED 09.01.2026
**Status:** Implemented

### Implemented:
- [x] **1b.2.1** `apply_stdp_with_timing()` updates `eligibility`, does NOT immediately change state
- [x] **1b.2.2** Novelty â†’ release dopamine (already existed)
- [x] **1b.2.3** `consolidate_eligibility(dopamine, time)` converts traces to changes
- [x] **1b.2.4** `_simulate_spike_pair()` calls `consolidate_eligibility()` with current DA level

### Files changed:
- `connection.py` â€” apply_stdp_with_timing() â†’ eligibility, consolidate_eligibility()
- `train.py` â€” _simulate_spike_pair() uses three-factor protocol

---

## PHASE 2: CA3 AS SHARED RECURRENT NETWORK [âœ… COMPLETED â€” 09.01.2026]
**Goal:** Pattern completion via SHARED recurrent network, NOT "attractor per episode"

### 2.1 CA3 Biology
- CA3 â€” **SHARED recurrent network** with recurrent collaterals
- Episode stores **index/set of CA3-neurons (engrams)**, weights are shared
- Completion = dynamics on shared matrix, not "retrieve attractor from episode"

### 2.2 Tasks
- [x] **2.2.1** CA3 module with shared recurrent_connections (not in Episode!) â†’ `ca3.py`
- [x] **2.2.2** Implement iterative dynamics on shared network:
  ```python
  class CA3:
      def __init__(self):
          self.recurrent_weights = {}  # SHARED weights
      
      def pattern_complete(self, cue: Set[str]) -> Set[str]:
          active = cue.copy()
          for _ in range(MAX_ITERATIONS):
              new_active = self._spread_recurrent(active)
              new_active = self._apply_inhibition(new_active)
              if new_active == active:
                  break
              active = new_active
          return active
  ```
  â†’ Implemented in `CA3.pattern_complete()`
- [x] **2.2.3** Episode stores `engram_neurons` (which CA3-neurons), NOT weights â†’ `input_neurons`
- [x] **2.2.4** Matching = overlap of active neurons with engram â†’ `_score_episodes()`
- [x] **2.2.5** `_word_to_episodes` â€” inverted index for O(1) lookup, not biological retrieval

### 2.3 Files
- `ca3.py` â€” **NEW** module with CA3 attractor dynamics
- `hippocampus.py` â€” `pattern_complete_attractor()` uses CA3
- `config.py` â€” `RETRIEVAL_MODE = "CA3"` (default)

### 2.4 Success test
```python
# Partial input should restore full pattern
cue = {"john", "garden"}  # 2 of 4 words
completed = hippocampus.pattern_complete_attractor(cue)
assert "went" in completed  # Restored via attractor
assert "to" in completed
```

### 2.5 Result [âœ… PASS]
```
CURRICULUM: 49/50 (98%)
STRICT: 3/3 (100%)
bAbI Task 1: 250/250 (100%)
FineWeb-Edu: 7/9 (77.8%)
[INFER-NO-LEARN]: PASS (0 LTM changes)
```

---

## PHASE 2.6: PFC LEARNABLE OPERATORS (Variant B) [ðŸ”´ TODO]
Status: DEFERRED. This phase is intentionally postponed until PHASE 3.6 (word order) and PHASE 3.7 (compositional reasoning) are stable under the non-regression contract.
**Goal:** Replace hand-coded question operators (e.g., composition/property/category) with a learnable PFC task-set mechanism that selects:
- The retrieval relation (`query_connector`) for top-down modulation.
- The content cue-set (`binding_tokens`) for hippocampal binding + CA3 scoring.

**Why (architectural intent):**
- Keep grammatical/task knowledge in PFC.
- Keep Hippocampus/CA3 purely content-driven (no operator word lists).
- Make operator selection emergent from experience (biologically plausible task-set learning).

### 2.6.1 Learning signal (no test-time learning)
- **Option B1 (self-supervised from memory):** derive pseudo-labels from the connector statistics of the successfully retrieved episode/edges.
  - Data source: existing episodes + their strongest semantic connectors (already stored during training).
  - Reward proxy: stable attractor + strong binding consistency + low competition.
- **Option B2 (weak supervision Qâ†’A):** use a small set of training QA pairs per operator type.
  - Reward: correct/incorrect answer match (dopamine/RPE analogue).

### 2.6.2 Data requirements
- No separate external dataset is strictly required if using **Option B1** (experience comes from the model's own episodic/semantic traces).
- If using **Option B2**, require a lightweight curated set of QA prompts to cover each operator family:
  - composition ("made of"), property ("color/size/shape"), category ("What is X?"), temporal (after/before), instrument (with).

### 2.6.3 Implementation tasks
- [ ] Add an **OperatorSelector** in PFC that maps a question representation to an operator state.
- [ ] Store/update operator preferences using a three-factor rule (eligibility Ã— dopamine) or a stable alternative compatible with `PlasticityMode`.
- [ ] Expose API in PFC:
  - `get_binding_tokens()` returns cues based on selected operator state.
  - `get_query_connector()` returns relation bias for top-down modulation.
- [ ] Ensure hippocampus/CA3 consume only PFC outputs (no operator heuristics outside PFC).

### 2.6.4 Validation (regression-safe)
- **Hard constraint:** `test_brain.py` must not retrain; operator learning happens only in training runs.
- Add a regression block that checks:
  - FineWeb-Edu remains â‰¥7/9 (77.8%).
  - CURRICULUM â‰¥49/50 (98%), GRADE1 64/64 (100%), bAbI 250/250 (100%).
  - Unknown queries still yield "I do not know" when evidence is weak.

---

## PHASE 3: API BOUNDARIES (Lexicon/InputLayer) [âœ… DONE â€” January 2026]
**Goal:** Explicit interfaces instead of global dictionary access

### 3.1 Important clarification
`WORD_TO_NEURON` is a **sensory system/lexical access**. In the brain this is also an index, implemented by anatomy. Removing completely = discarding sensory system.

### 3.2 Correct approach
- **Keep** `WORD_TO_NEURON` as input sensory pathway
- **Forbid** any module except `InputLayer/Lexicon` from reading this dict
- **Pass** only neurons, not strings

### 3.3 Tasks
- [x] **3.3.1** Create `InputLayer.get_neuron(word)`, `get_neurons(words)`, `get_neuron_ids(words)` â€” public interface
  â†’ Implemented in lexicon.py (InputLayer class)
- [x] **3.3.2** All modules receive **only neurons**, not strings
  â†’ CA3/Hippocampus receive word_to_neuron as parameter, not global access
  â†’ Docstrings updated to reference Lexicon.raw_dict
- [x] **3.3.3** `_word_to_episodes` â€” marked as **engineering index**
  â†’ hippocampus.py: WARNING comment added (lines 101-106)
- [x] **3.3.4** Add `OutputLayer` for generation (reverse path)
  â†’ Implemented in lexicon.py (OutputLayer class)
- [x] **3.3.5** Contract: train.py uses LEXICON global, _refresh_lexicon() after load/train
  â†’ train.py: LEXICON variable + _refresh_lexicon() function

### 3.4 Files
- [x] New: `lexicon.py` â€” InputLayer/OutputLayer/Lexicon classes (310 lines)
- [x] `train.py` â€” LEXICON global + _refresh_lexicon() after load_model_numpy and train_full_pipeline
- [x] `hippocampus.py` â€” `_word_to_episodes` marked as engineering optimization
- [x] `ca3.py` â€” docstrings updated to reference Lexicon

### 3.5 Implementation (January 2026)
```python
# lexicon.py provides:
# - InputLayer: get_neuron(), get_neurons(), get_neuron_ids(), get_neuron_set()
# - OutputLayer: get_word(), get_words(), get_words_set(), generate_sequence()
# - Lexicon: combined interface with raw_dict for backward compatibility

# train.py:
# - LEXICON: Lexicon = None  # initialized by _refresh_lexicon()
# - _refresh_lexicon() called after load_model_numpy() and train_full_pipeline()
```

BIOLOGY (Hickok & Poeppel 2007, Dual Stream Model):
- InputLayer = ventral stream (sound â†’ meaning)
- OutputLayer = dorsal stream (meaning â†’ sound)

### 3.6 Motor Output / Sequence Generator (Word Order) [âœ… DONE â€” January 2026]
Goal:
- Ensure generated answers preserve correct token order, not a bag-of-words.
- Ensure sequence constraints exist inside retrieval/pattern completion (order is part of the memory trace).

Scope:
- (A) Episode-level order: store and replay `Episode.input_words` as an ordered trace â€” âœ… DONE (PHASE 3.8)
- (B) Pattern/attractor-level order: allow retrieval to reconstruct ordered chains, not only sets â€” âœ… DONE

IMPLEMENTATION (January 2026):
1. **motor_output.py** â€” NEW module (210 lines):
   - `SequenceGenerator` class â€” Broca's area analogue
   - `generate_answer_ordered()` â€” main function
   - Uses TIME CELL order from `Episode.input_words`
   - Inserts connectors between content words via `_insert_connectors()`
   - Excludes query words (lateral inhibition)

2. **train.py integration**:
   - `ask()` now calls `generate_answer_ordered()` instead of `generate_answer_from_episode()`
   - Preserves original encoding order, not connection-based traversal

BIOLOGY (Hickok & Poeppel 2007, Dual Stream Model):
- Dorsal stream: meaning â†’ motor plans â†’ articulation
- Broca's area: sequencing and grammatical encoding
- Motor cortex: actual speech production

Success criteria (regression-safe):
- Add deterministic tests that assert exact token order for a fixed set of prompts.
- Keep 376/376 passing.

### 3.7 Compositional WM reasoning (Text Understanding) [âœ… DONE â€” January 2026]
Goal:
- Answer multi-hop questions (2-3 supporting facts) using PFC as a scratchpad, without learnable operators.

Mechanism:
- Iterate: retrieve -> write bindings/entities into PFC -> retrieve again with updated cues -> stop on stability.

IMPLEMENTATION (January 2026):
1. **pfc.py** â€” new methods:
   - `get_multi_hop_cues(query_words)` â€” returns expanded cues (query + PFC contents)
   - `add_retrieval_result(episode_words, query_words)` â€” stores intermediate result

2. **train.py** â€” new function:
   - `ask_multi_hop(question, max_hops=3)` â€” iterative retrieval with PFC scratchpad
   - Loop detection via `seen_episodes` set
   - Stops when no new info or max hops reached

BIOLOGY (Miller & Cohen 2001, Compositional WM):
- PFC holds intermediate results during reasoning
- Each hop retrieves a fact and adds entities to PFC
- Next retrieval uses union of query + PFC contents
- Process repeats until answer found or no progress

Example (bAbI Task 2 - two supporting facts):
- Q: "Where is the football?"
- Hop 1: retrieve "John picked up the football" â†’ add "john" to PFC
- Hop 2: retrieve "John went to garden" â†’ answer "garden"

Success criteria (regression-safe):
- Add a small curated multi-hop test set with explicit expected answers.
- Keep 376/376 passing.

---

## PHASE 4: BASAL GANGLIA (Go/NoGo/STN) [âœ… DONE]
**Goal:** Real Go/NoGo/STN architecture for action selection
**Status:** COMPLETE - Full BG circuit in `basal_ganglia.py`, integrated into `ask()` pipeline

### 4.1 BG Biology
```
Cortex â†’ Striatum (D1=Go, D2=NoGo) â†’ GPi/GPe â†’ Thalamus â†’ Cortex
                    â†“
                   STN (Hyperdirect) â†’ GPi (stop signal)
```

### 4.2 Tasks
- [x] **4.2.1** Base class `BasalGangliaThalamusGating` in `basal_ganglia.py`
- [x] **4.2.2** D1/D2/GPe/GPi/STN/Thalamus computations in `select_action()`
- [x] **4.2.3** Striatum with D1 (Go) and D2 (NoGo) MSNs â€” implemented inline
- [x] **4.2.4** GPi/GPe tonic inhibition of thalamus â€” gpi_tonic, gpe_tonic
- [x] **4.2.5** STN hyperdirect pathway (fast stop) â€” stn_global, conflict detection
- [x] **4.2.6** Neuromodulators (DA/ACh/NE/5-HT) modulate all pathways
- [x] **4.2.7** Integrate into `ask()` for action selection â€” BASAL_GANGLIA global

### 4.3 Implementation Details
```python
# In train.py _ask_impl():
BASAL_GANGLIA.select_action(
    ["retrieve", "multi_hop"],
    context={"retrieve": 0.8, "multi_hop": salience},
    neuromodulators={"DA": ..., "ACh": 0.5, "NE": ..., "5HT": 0.3}
)
# BG selects cognitive strategy based on cortical salience and neuromodulator state
```

### 4.4 Success test
```python
# BG selects between retrieve and multi_hop strategies
# Test: 411/424 (97.0%) after integration
bg.select_action(["retrieve", "multi_hop"])
# Selected action depends on context salience and DA/ACh/NE/5HT levels
```

---

## PHASE 5: NEUROMODULATOR EXPANSION [âœ… DONE â€” January 2026]
**Goal:** ACh, NE, 5-HT beyond DA (base three-factor in PHASE 1b)

### 5.1 Neuromodulators
| Modulator | Role | When |
|-----------|------|-------|
| **Dopamine** | Reward prediction error | Reward/novelty |
| **ACh** | Attention gating | Encoding new information |
| **NE** | Alertness/uncertainty | Unexpected input |
| **5-HT** | Patience/temporal discounting | Delayed reward |

### 5.2 Tasks
- [x] **5.2.1** ACh enhances encoding (more eligibility with attention)
  - Implemented: _release_acetylcholine(), _get_acetylcholine_modifier()
  - ACh released at start of learning (attention gate open)
  - ACh amplifies eligibility traces during encoding
- [x] **5.2.2** NE modulates exploration vs exploitation
  - Implemented: _release_norepinephrine(), _get_norepinephrine_modifier()
  - NE released on novel connections and unexpected input
  - High NE boosts new/weak connections (exploration)
- [x] **5.2.3** 5-HT affects temporal discounting
  - Implemented: _release_serotonin(), _get_serotonin_modifier()
  - 5-HT released for long sentences (patience)
  - High 5-HT slows learning but stabilizes
- [x] **5.2.4** Integrate with NeuromodulatorSystem in activation.py
  - Already integrated via BrainOscillator and NeuromodulatorSystem
  - BG uses all 4 neuromodulators for action selection

### 5.3 Files Modified
- train.py â€” Added ACh/NE/5-HT systems analogous to DA
  - _release_acetylcholine(), _update_acetylcholine(), _get_acetylcholine_modifier()
  - _release_norepinephrine(), _update_norepinephrine(), _get_norepinephrine_modifier()
  - _release_serotonin(), _update_serotonin(), _get_serotonin_modifier()
  - _get_combined_learning_modifier() â€” multiplicative effect of all 4
  - _update_all_neuromodulators() â€” batch update
  - _get_neuromodulator_levels() â€” for BG integration
- _simulate_spike_pair() updated for Four-Factor Learning
- train_sentence_with_context() updated with release conditions

### 5.4 Biological References
- Hasselmo 2006: ACh enhances encoding in hippocampus
- Hasselmo & Sarter 2011: ACh attention gating
- Sara 2009: NE and locus coeruleus in attention/arousal
- Aston-Jones & Cohen 2005: NE exploration vs exploitation
- Dayan & Huys 2008: 5-HT and behavioral inhibition
- Miyazaki et al. 2014: 5-HT and patience for delayed rewards

### 5.5 Test Results (verified 2026-01-21)
- CURRICULUM: 47/50 (94%) â€” improved from 46/50 (92%)
- PRESCHOOL: 42/48 (87.5%) â€” improved from 41/48 (85.4%)
- GRADE1: 64/64 (100%)
- No regressions in core functionality

---

## PHASE 6: TRUE REPLAY / SWR [âœ… DONE â€” January 2026]
**Goal:** Sharp Wave-Ripples with temporal compression

### 6.1 SWR Biology
- During rest/sleep CA3 spontaneously reactivates patterns
- **Temporal compression:** 10-20x faster than original
- **Reverse replay:** sometimes in reverse order (for planning)
- SWR â†’ coordinated reactivation â†’ synaptic consolidation

### 6.2 Tasks
- [x] **6.2.1** `replay()` should **reactivate spike patterns**, not increment counters
  â†’ Implemented: `_swr_event()` generates spike times with temporal compression
- [x] **6.2.2** Temporal compression: replay faster than encoding
  â†’ Implemented: `SWR_TEMPORAL_COMPRESSION = 15` (original 100ms â†’ ~6.7ms)
- [x] **6.2.3** Add `sleep_phase` enum: `WAKE`, `NREM`, `REM`
  â†’ Implemented in config.py: `SleepPhase` enum with biological references
- [x] **6.2.4** NREM: SWR + slow oscillations â†’ memory consolidation
  â†’ Implemented: `_nrem_replay_cycle()` with forward/reverse replay
- [x] **6.2.5** REM: random reactivation â†’ memory integration
  â†’ Implemented: `_rem_reactivation_cycle()` for cross-memory associations
- [x] **6.2.6** Downscaling after sleep (synaptic homeostasis)
  â†’ Implemented: `_apply_synaptic_downscaling()` with Tononi & Cirelli 2006

### 6.3 Files Modified
- `config.py` â€” SleepPhase enum, SWR parameters (temporal compression, reverse prob, etc.)
- `hippocampus.py` â€” Complete rewrite of sleep():
  - `sleep()` now alternates NREM/REM cycles (ratio configurable)
  - `_nrem_replay_cycle()` â€” SWR replay with temporal compression
  - `_rem_reactivation_cycle()` â€” random reactivation for integration
  - `_swr_event()` â€” generates spike times with compression, forward/reverse
  - `_apply_synaptic_downscaling()` â€” synaptic homeostasis
  - `_replay_episode()` â€” now delegates to `_swr_event()`
- `train.py` â€” `sleep_consolidation()` updated for new statistics

### 6.4 Implementation Details

**Temporal Compression (NÃ¡dasdy et al. 1999):**
```python
# Original encoding: ~100ms between words
# SWR replay: ~6.7ms between spikes (compression factor 15x)
compressed_interval = original_interval / CONFIG["SWR_TEMPORAL_COMPRESSION"]
```

**Reverse Replay (Diba & BuzsÃ¡ki 2007):**
```python
# ~30% of replays are in reverse order (planning, backward chaining)
is_reverse = np.random.random() < CONFIG["SWR_REVERSE_REPLAY_PROB"]
if is_reverse:
    sequence = sequence[::-1]
```

**NREM/REM Alternation (Born & Wilhelm 2012):**
```python
# NREM dominates early sleep, REM increases later
# Default ratio 4:1 (NREM:REM)
is_nrem = (cycle_idx % (nrem_to_rem_ratio + 1)) != nrem_to_rem_ratio
```

**Synaptic Homeostasis (Tononi & Cirelli 2006):**
```python
# Global downscaling preserves relative strength
# Only non-MYELINATED connections are downscaled
conn.forward_usage = max(min_strength, int(conn.forward_usage * 0.95))
```

**Stochastic Episode Selection (Wilson & McNaughton 1994, Foster & Wilson 2006):**
```python
# WHY RANDOM? Biological justification:
# 1. SWR events are spontaneous, triggered by network state, not deterministic
#    (BuzsÃ¡ki 2015: "SWRs emerge stochastically from CA3 recurrent dynamics")
# 2. Not all episodes replay every night â€” prioritized by recency/salience
#    (Wilson & McNaughton 1994: "subset of experiences replayed")
# 3. Variability in replay promotes generalization, prevents overfitting
#    (Foster & Wilson 2006: "stochastic sampling aids memory abstraction")
# 4. Weighted sampling: recent/important episodes have higher replay probability
#    (Prioritized Experience Replay has biological basis in dopamine modulation)

# Implementation: weighted random sampling by recency + replay count
weights = [recency_weight(ep) * replay_priority(ep) for ep in candidates]
episode = np.random.choice(candidates, p=normalize(weights))
```

**NOTE:** This means each training run produces slightly different weights (~1% variance
in test results). This is biologically realistic â€” human memory is not perfectly
deterministic. For reproducibility, set `random.seed()` before training.

### 6.5 Biological References
- BuzsÃ¡ki, G. (2015). "Hippocampal sharp wave-ripple: A cognitive biomarker."
  Nature Neuroscience, 18(9), 1237-1247.
- Diba, K., & BuzsÃ¡ki, G. (2007). "Forward and reverse hippocampal place-cell
  sequences during ripples." Nature Neuroscience, 10(10), 1241-1242.
- NÃ¡dasdy, Z., et al. (1999). "Replay and time compression of recurring spike
  sequences in the hippocampus." Journal of Neuroscience, 19(21), 9497-9507.
- Tononi, G., & Cirelli, C. (2006). "Sleep function and synaptic homeostasis."
  Sleep Medicine Reviews, 10(1), 49-62.
- Born, J., & Wilhelm, I. (2012). "System consolidation of memory during sleep."
  Psychological Research, 76(2), 192-203.
- Poe, G.R., et al. (2000). "Experience-dependent phase-reversal of hippocampal
  neuron firing during REM sleep." Brain Research, 855(1), 176-180.
- Wilson, M.A., & McNaughton, B.L. (1994). "Reactivation of hippocampal ensemble
  memories during sleep." Science, 265(5172), 676-679.
- Foster, D.J., & Wilson, M.A. (2006). "Reverse replay of behavioural sequences
  in hippocampal place cells during the awake state." Nature, 440(7084), 680-683.

### 6.6 Test Results (verified 2026-01-21)
- CURRICULUM: 48/50 (96.0%)
- PRESCHOOL: 43/48 (89.6%)
- GRADE1: 64/64 (100%)
- STRICT: 3/3 (100%)
- FineWeb-Edu: 6/9 (66.7%)
- TOTAL: 164/174 (94.3%) â€” no regressions

---

## PHASE 7: INTERNAL ACTIONS [âœ… DONE â€” January 2026]
**Goal:** Thinking strategy selection via BG

### 7.1 Biology (Redgrave et al. 2010, Hikosaka et al. 2014)
Brain chooses between **cognitive actions** using the same Go/NoGo circuitry:
- Dorsolateral striatum: motor habits
- Dorsomedial striatum: goal-directed actions
- Ventral striatum: motivation/reward

The BG gates which cognitive program executes, not just motor actions.

### 7.2 Tasks
- [x] **7.2.1** Define set of internal actions:
  ```python
  class InternalAction(Enum):
      RETRIEVE = auto()      # Pattern complete from hippocampus (habitual)
      MULTI_HOP = auto()     # PFC-guided multi-step reasoning (goal-directed)
      INFER = auto()         # Spread activation and derive (exploratory)
      CLARIFY = auto()       # Ask for more information (future)
      WAIT = auto()          # Delay response, gather more (future)
  ```
  â†’ Implemented in `basal_ganglia.py` (InternalAction enum)
- [x] **7.2.2** BG selects action based on context + neuromodulators
  â†’ `select_cognitive_action()` method in BasalGangliaThalamusGating
- [x] **7.2.3** PFC holds current action as goal
  â†’ Goal set via `PREFRONTAL_CORTEX.set_goal()` with action metadata
- [ ] **7.2.4** Learning: reward â†’ update BG weights for action selection
  â†’ TODO: Requires reinforcement learning integration
- [x] **7.2.5** `ask()` should call action selection, not hardcoded pipeline
  â†’ `ask()` now uses `select_cognitive_action()` with InternalAction enum

### 7.3 Files Modified
- `basal_ganglia.py` â€” InternalAction enum, select_cognitive_action() method
- `train.py` â€” ask() integrated with InternalAction selection

### 7.4 Test Results (verified 2026-01-21)
- CURRICULUM: 48/50 (96%) â€” improved from 46/50
- PRESCHOOL: 43/48 (89.6%) â€” improved from 41/48
- GRADE1: 64/64 (100%)
- STRICT: 3/3 (100%)
- FineWeb-Edu: 6/9 (66.7%)
- TOTAL: 165/174 tests passing

### 7.5 INFER Implementation (Semantic Inference)
BIOLOGY (Tulving 1972 - Episodic vs Semantic Memory):
- When episodic retrieval fails, use semantic memory (general knowledge)
- Semantic inference uses strong MYELINATED connections between concepts
- Convergent evidence required: answer must be supported by MULTIPLE query words

Implementation in `_attempt_inference()`:
1. Collect evidence from ALL query content words
2. Score by synaptic strength (MYELINATED Ã— 3.0, usage count)
3. **Convergent evidence check** (Treisman 1996): if â‰¥2 content words, require â‰¥2 sources
4. Return multi-word answer from top-K related concepts

Example:
- "What happens when you touch fire?" â†’ touchâ†’burn, fireâ†’burn (convergent) â†’ "burn" âœ…
- "Who is the president of Mars?" â†’ presidentâ†’country, Marsâ†’planet (no convergence) â†’ "I do not know" âœ…

### 7.6 Known Limitations
- CLARIFY/WAIT actions not yet integrated (require dialog system)
- Some questions still fail due to retrieval issues (not inference)

### 7.7 References
- Redgrave, P., et al. (2010). "Goal-directed and habitual control in the basal ganglia"
  Nature Reviews Neuroscience, 11(11), 760-772.
- Hikosaka, O., et al. (2014). "Basal ganglia circuits for reward value-guided behavior"
  Annual Review of Neuroscience, 37, 289-306.
- Tulving, E. (1972). "Episodic and semantic memory." In Organization of Memory.
- Treisman, A. (1996). "The binding problem." Current Opinion in Neurobiology, 6(2), 171-178.
- Collins, A.M. & Loftus, E.F. (1975). "A spreading-activation theory of semantic processing."
  Psychological Review, 82(6), 407-428.

---

## PHASE 8: LEARN VERB_FORMS [DEFERRED]
**Goal:** Morphology through learning, not hardcode
**Status:** DEFERRED â€” Current VERB_FORMS works correctly and is biologically grounded
           (like Chomsky's Universal Grammar â€” innate language structures).
           Priority: LOW. Will implement when higher-priority phases complete.

### 8.1 Biology
Children **learn** morphological rules through exposure:
- Hear "go", "goes", "went" in different contexts
- Form connections between forms
- Over-regularization errors ("goed") show this is learned, not innate

### 8.2 Tasks
- [ ] **8.2.1** Remove hardcoded `VERB_FORMS` dict
- [ ] **8.2.2** During learning: verb forms create **mutual connections**
  ```python
  # "John goes to school" + "John went to school"
  # â†’ connection goesâ†”went via shared context {john, school}
  ```
- [ ] **8.2.3** During retrieval: activating "went" automatically activates "goes" via connections
- [ ] **8.2.4** Morphological priming = spreading activation
- [ ] **8.2.5** Add to curriculum: pairs of sentences with different forms

### 8.3 Files
- `hippocampus.py` â€” remove `VERB_FORMS`, use activation
- `curriculum.py` â€” add morphological pairs

### 8.4 Success test
```python
# Query "went" should find episodes with "goes" via learned connections
# WITHOUT hardcoded dictionary
```

---

## PHASE 9: ADDITIONAL IMPROVEMENTS

### 9.1 DG Pattern Separation [âœ… DONE â€” January 2026]
- [x] Remove `hash()` from `pattern_separate()`
- [x] Implement via sparse coding + random projections + WTA
- [x] Add DentateGyrus class with biologically plausible mechanism

**BIOLOGY (Rolls et al., 2007; Leutgeb et al., 2007; Treves & Rolls, 1994):**
- Perforant path from EC â†’ DG (random-like projections)
- Each granule cell receives ~0.5% of EC inputs (sparse connectivity)
- Granule cells have very low activity (~2% sparsity)
- Winner-Take-All via inhibitory interneurons (lateral inhibition)
- Pattern separation: similar inputs â†’ orthogonal sparse representations

**IMPLEMENTATION:**
- `DentateGyrus` class in `hippocampus.py`
- Random projection weights generated deterministically from neuron_id
  (simulates fixed anatomical connectivity established during development)
- Granule cell activation = weighted sum of inputs
- Top-k% granule cells survive (WTA via lateral inhibition)
- Neurons projecting to winning granule cells are selected
- Experience bonus: neurons with MYELINATED connections win ties

**FILES MODIFIED:**
- `hippocampus.py` â€” Added DentateGyrus class, updated pattern_separate()
- `config.py` â€” DG_SPARSITY parameter (already existed, now used correctly)

### 9.2 CA1 Output Layer [âœ… DONE â€” January 22, 2026]
- [x] CA1 as separate stage between CA3 and Cortex
- [x] CA1 projects to entorhinal cortex and PFC

**BIOLOGY (Amaral & Witter 1989, Naber et al. 2001):**
- CA1 is the primary output layer of hippocampus
- Receives from CA3 via Schaffer collaterals (70%)
- Receives direct EC Layer III input (temporoammonic pathway, 30%)
- Projects to EC Layer V for consolidation
- Projects directly to PFC for working memory

**IMPLEMENTATION:**
- `ca1.py` â€” New CA1 class with readout, project_to_pfc, project_to_ec methods
- `hippocampus.py` â€” Added _ca1 dependency, retrieve_via_ca1(), get_pfc_projection()
- `config.py` â€” CA1_SCHAFFER_WEIGHT, CA1_EC_DIRECT_WEIGHT, CA1_OUTPUT_THRESHOLD

### 9.3 Developmental Phases [âœ… DONE â€” January 22, 2026]
- [x] Critical periods: windows of heightened plasticity for specific learning
- [x] Experience-expectant plasticity: learning bonuses during critical periods
- [x] Developmental pruning: unused connections eliminated

**BIOLOGY (Hensch 2005, Hubel & Wiesel 1970, Huttenlocher 1979):**
- Four stages: INFANT, CHILD, ADOLESCENT, ADULT
- Critical periods for LANGUAGE, SEMANTIC, SYNTACTIC, SOCIAL
- Plasticity decreases with age (2.0 â†’ 1.5 â†’ 1.0 â†’ 0.8)
- Pruning peaks in ADOLESCENT stage
- PV interneuron maturation closes critical periods

**IMPLEMENTATION:**
- `development.py` â€” DevelopmentalStage enum, CriticalPeriodType, DevelopmentManager
- `config.py` â€” DEVELOPMENTAL_STAGE, DEV_THRESHOLD_* parameters

### 9.4 PFC Persistent Activity [âœ… DONE â€” January 2026]
- [x] Sustained firing via recurrent excitation
- [x] NMDA-dependent maintenance
- [x] Distractor resistance

**BIOLOGY (Wang 2001, Compte et al. 2000, Miller & Cohen 2001):**
- PFC maintains active representations through recurrent excitation
- Pyramidal neurons form self-sustaining circuits (attractor dynamics)
- NMDA receptors have slow kinetics (tau ~100ms vs AMPA ~5ms)
- This slow decay enables persistent activity (sustained firing)
- GABAergic interneurons create inhibitory barrier against distractors
- Goal-relevant inputs bypass barrier via top-down facilitation

**IMPLEMENTATION:**
- `PFCSlot.decay()` â€” NMDA-like slow decay (blended: 30% AMPA + 70% NMDA)
- `PFCSlot.recurrent_boost()` â€” activation boost from related slots
- `PFC._apply_recurrent_excitation()` â€” mutual boosting between slots sharing content
- `PFC._can_enter_against_distractors()` â€” inhibitory gating for new inputs
- `PFC.add_context(force=)` â€” parameter to bypass distractor resistance

**CONFIG PARAMETERS:**
- `PFC_NMDA_DECAY`: 0.95 â€” slow NMDA decay rate
- `PFC_RECURRENT_STRENGTH`: 0.15 â€” recurrent connection strength
- `PFC_DISTRACTOR_THRESHOLD`: 0.7 â€” barrier strength for distractors
- `PFC_RECURRENT_MIN_ACTIVATION`: 0.3 â€” minimum activation for recurrence

**FILES MODIFIED:**
- `pfc.py` â€” Added persistent activity mechanisms
- `config.py` â€” Added PFC persistent activity parameters
- `test_brain.py` â€” Added test_pfc_persistent_activity()

---

## PHASE 10: TEST/DATA INVESTIGATION [TODO â€” after all phases]
**Goal:** Investigate failing tests, data quality, and expectations

### 10.1 Failing Tests Analysis
Current failing tests (21.01.2026):
- [ ] `What color is an orange?` â€” CURRICULUM, should be "orange"
- [ ] `What is ice?` â€” CURRICULUM, should be "frozen water"
- [ ] `What happens when ice gets warm?` â€” PRESCHOOL
- [ ] `What happens when you fall?` â€” PRESCHOOL
- [ ] `When should you wash your hands?` â€” PRESCHOOL
- [ ] `What month comes after January?` â€” PRESCHOOL
- [ ] `What is the opposite of in?` â€” PRESCHOOL
- [ ] `What color is chlorophyll?` â€” FineWeb
- [ ] `What is sedimentary rock made of?` â€” FineWeb

### 10.2 Investigation Results [DONE â€” January 22, 2026]

**Summary:** Facts EXIST in data and ARE encoded as CONSOLIDATED episodes. Problem is in retrieval scoring.

| Failing Test | Data Exists? | Episode Exists? | Root Cause |
|--------------|--------------|-----------------|------------|
| What color is an orange? | âœ… `("orange", "orange")` | âœ… but rainbow competes | **Homonym** + Episode competition |
| What is ice? | âœ… "Ice is frozen water" | âœ… CONSOLIDATED | **Connector mismatch**: queryâ†’`is_a`, dataâ†’`is` |
| What happens when ice gets warm? | âœ… "When ice gets warm it melts" | âœ… CONSOLIDATED | Wrong episode wins scoring |
| What month comes after January? | âœ… | âœ… | Sequence edge case |

**Key Findings:**
1. **Connector Mismatch** â€” "What is X?" extracts `query_connector='is_a'`, but data creates connector `'is'`
   - Attempted fix: `is_a` â†’ `is` matching â†’ caused regression (3 new failures)
   - Needs more careful fix in query extraction logic, not in matching
   
2. **Episode Competition** â€” Multiple similar episodes, scoring doesn't always pick correct one
   - `['ice', 'frozen', 'water']` vs `['ice', 'cold', 'slippery']` both CONSOLIDATED with replay=5
   
3. **Homonym Resolution** â€” No word sense disambiguation
   - "orange" = fruit AND color, rainbow episode contains both

**Recommendations (future work):**
- [ ] Fix query connector extraction: "What is X?" should use `'is'` not `'is_a'`
- [ ] Add specificity bonus for shorter/more specific episodes
- [ ] Implement context-dependent activation for homonyms

### 10.3 Test Expectations Review
- [x] Expected answers are correct and fair
- [x] Multiple valid answers already accepted (lists in expected)
- [ ] Some tests may be too specific for current retrieval

### 10.4 Data Quality
- [x] curriculum.py has the facts
- [x] preschool_world.py has the facts
- [ ] FineWeb coverage incomplete for some tested facts

### 10.5 Known Limitations & Open Issues

#### Retrieval Issues (causing failing tests)
| Issue | Impact | Affected Tests | Proposed Fix |
|-------|--------|----------------|--------------|
| **Connector Mismatch** | "What is X?" extracts `is_a`, data has `is` | What is ice?, What is water? | Change query extraction: `is_a` â†’ `is` |
| **Episode Competition** | Multiple similar episodes, wrong one wins | What happens when ice gets warm? | Add specificity bonus for shorter episodes |
| **Homonym Ambiguity** | No word sense disambiguation | What color is an orange? | Context-dependent activation from PFC |
| **Sequence Edge Cases** | Temporal queries at boundaries | What month comes after January? | Improve `after` connector handling |

#### Training Variance
- Stochastic replay causes ~1% variance between training runs
- Some facts may not consolidate due to random episode selection
- Episode order during training affects which episodes get replayed

#### Data Gaps
- FineWeb coverage incomplete for some scientific facts (chlorophyll, sedimentary rock)
- Some antonyms not explicitly encoded (opposite of "in")
- Cause-effect relations may need more explicit encoding

#### Architectural Limitations (CRITICAL)

**ROOT CAUSE: No Syntactic Parsing / Semantic Role Labeling**

The model finds related concepts but doesn't understand sentence structure:

| Question | Model Answer | Problem |
|----------|--------------|---------|
| "Is a turtle faster than a rabbit?" | "rabbit faster turtle" | Correct concepts, wrong SUBJECT (question about turtle, not rabbit) |
| "What does the Earth go around?" | "moon goes" | Wrong DIRECTION (Moonâ†’Earth, not Earthâ†’Sun) |

**What's missing:**
1. **Syntactic parsing** â€” who is subject? who is object?
2. **Semantic role labeling** â€” agent, patient, action
3. **Direction-aware connections** â€” Aâ†’B vs Bâ†’A

**Biological equivalent:**
- **Broca's area** â€” syntactic processing
- **Wernicke's area** â€” semantic comprehension
- **Binding** â€” role assignment via gamma oscillations (Fries 2005)

**PHASE 11 IMPLEMENTED** (January 22, 2026):
- âœ… broca.py: SyntacticProcessor for subject/predicate extraction
- âœ… Subject bonus in CA3 scoring
- âœ… Binary choice handling
- Result: 165/174 (+1)

---

#### Language Interpretation Limitations (Rule-Based Parsing)

**IMPORTANT**: The model uses rule-based parsing for language interpretation instead of 
learned linguistic knowledge. This is a necessary simplification because:

1. **No large-scale language training** â€” The brain model is trained on ~1,000 basic sentences 
   (plus 40K from FineWeb-Edu), not millions/billions like LLMs. A human child learns language from ~10M words by age 6.

2. **Rule-based components** (necessary "hacks"):
   - `broca.py` â€” hardcoded syntactic patterns ("What is X?", "Is X Y or Z?")
   - `pfc.py` â€” question type classification via keyword matching
   - `lexicon.py` â€” function word lists (articles, prepositions)
   - `motor_output.py` â€” connector insertion rules

3. **Why this is acceptable**:
   - Even biological Broca's area has innate structure (Universal Grammar hypothesis)
   - Rule-based parsing mimics what would be learned from massive language exposure
   - The MEMORY and REASONING systems are fully learned, only PARSING is rule-based

4. **Future improvement** (if more training data available):
   - Replace rule-based parsing with learned syntactic patterns
   - Train on CHILDES corpus (child-directed speech)
   - Implement statistical parsing like humans learn implicitly

**Analogy**: Like a human who knows facts but speaks with an accent â€” 
the knowledge is real, only the interface is simplified.

---

Other limitations:
- No explicit word sense disambiguation (homonyms compete in activation)
- Connector matching is binary (match/no-match), no partial credit
- PFC context not fully utilized for episode selection bias
- CA3 scoring doesn't prioritize more specific episodes over general ones

#### Biological Simplifications
- NMDA receptor kinetics simplified (no MgÂ²âº block dynamics)
- Dendritic computation limited (no backpropagating action potentials)
- Neuromodulator interactions simplified (no receptor subtypes)
- Sleep phases simplified (no ultradian cycling)

---

## EXECUTION ORDER (UPDATED 22.01.2026)

```
âœ… PHASE 0 (PlasticityMode LEARN/INFER) â€” DONE
âœ… PHASE 1 (STDP/HH) â€” DONE
âœ… PHASE 1b (Three-Factor) â€” DONE
âœ… PHASE 2 (CA3 shared network) â€” DONE
âœ… PHASE 3 (API boundaries) â€” DONE
âœ… PHASE 4 (BG integration) â€” DONE
âœ… PHASE 5 (ACh/NE/5-HT expansion) â€” DONE
âœ… PHASE 6 (Replay/SWR) â€” DONE
âœ… PHASE 7 (Internal Actions) â€” DONE
âœ… PHASE 9.1 (DG Pattern Separation) â€” DONE (January 2026)
âœ… PHASE 9.2 (CA1 Output Layer) â€” DONE (January 22, 2026)
âœ… PHASE 9.3 (Developmental Phases) â€” DONE (January 22, 2026)
âœ… PHASE 9.4 (PFC Persistent Activity) â€” DONE (January 2026)
âœ… PHASE 10 (Test/Data Investigation) â€” DONE (January 22, 2026)
   - ROOT CAUSE FOUND: No syntactic parsing / semantic role labeling
   - Model finds concepts but doesn't understand subject/object/direction

â¸ï¸ PHASE 8 (Learned Morphology) â€” DEFERRED (LOW priority)

âœ… PHASE 11 (Syntactic Processing / Broca's Area) â€” DONE (January 22, 2026)
   - broca.py: SyntacticProcessor for subject/predicate extraction
   - Subject bonus in CA3 scoring (Friederici 2011)
   - Binary choice handling (don't exclude options from answer)
   - Result: 165/174 (+1 from 164)

âœ… PHASE 12 (Cause-Effect Relations) â€” DONE (January 22, 2026)
   - broca.py: Added cause-effect pattern parsing for "What happens when X?"
   - train.py: Added cause_effect query_connector
   - ca3.py: Added cause-effect filtering (episode MUST contain cause subject)
   - answer_generation: Exclude cause words, keep only effect
   - Result: 166/174 (+1 from 165)
   - LIMITATION: Word sense disambiguation (fall=autumn vs fall=to fall) not solved

âœ… PHASE 13 (Temporal Sequence Fix) â€” DONE (January 22, 2026)
   - train.py: Exclude question words from temporal answer candidates
   - "What month comes after January?" â†’ was returning "month" (usage=52), now returns "february" (usage=48)
   - BIOLOGY: Answer should be NEW information, not echo of question
   - Result: 167/174 (+1 from 166)

âœ… PHASE 14 (Antonym Relations) â€” DONE (January 22, 2026)
   - train.py: Encode opposite relations with connector='opposite'
   - Bidirectional connections Xâ†”Y for antonyms
   - Retrieval follows typed connections
   - Works for function words ("in"/"out")
   - Result: 169/174 (+2 from 167)

âœ… PHASE 15 (Iterative Retrieval) â€” DONE (January 22, 2026)
   - pfc.py: IterativeRetriever class for PFC-Hippocampus reasoning loop
   - RetrievalResult dataclass with confidence and history
   - PFC maintains goal, iteratively queries hippocampus
   - Each retrieval adds context to working memory
   - Confidence = goal overlap + consolidation bonus
   - Max iterations: 4 (biology: humans do 2-4 retrieval cycles)
   - INTEGRATED into main ask(): activates when direct retrieval fails
   - Also used by ask_multi_hop() for explicit multi-step reasoning
   - BIOLOGY: Preston & Eichenbaum 2013, Eichenbaum 2017, Miller & Cohen 2001

ðŸ“Š Model at 169/174 (97.1%) â€” GRADE1 100%, bAbI 100%
```

---

## MANDATORY METRICS (for audit)

| Metric | Description | How to verify |
|---------|----------|---------------|
| **[INFER-NO-LEARN]** | ask() does not change LTM | Compare connection state before/after ask() |
| **[REPRO]** | Same question â†’ same raw output | No RNG in retrieval |
| **[CA3-DYNAMICS]** | Completion via iterations, not argmax | Log number of iterations until stability |
| **[BG-ACTIONS]** | BG selects different actions in different contexts | Log shows different choices + changes after reward |

---

## SUCCESS METRICS BY PHASE

| Phase | Metric |
|-------|--------|
| 0 | Test [INFER-NO-LEARN] passes |
| 1 | âœ… STDP called during learning, accumulated_stdp_strength != 0 |
| 2 | Pattern completion via iterations, not argmax |
| 3 | BG selects actions, D1/D2 pathways work |
| 4 | Inference without direct access to WORD_TO_NEURON |
| 5 | Eligibility Ã— DA = weight change |
| 6 | Replay reproduces spike patterns |
| 7 | ask() chooses between retrieve/infer/clarify |
| 8 | VERB_FORMS empty, morphology via connections |

---

## RISKS

| Risk | Mitigation |
|------|-----------|
| Spiking too slow | Use LIF, batch processing |
| Attractors don't converge | Tune inhibition, add noise |
| BG too complex | Start with minimal viable BG |
| Locality breaks accuracy | Keep index as fallback |
| Three-factor unstable | Gradually increase DA influence |

---

Start with **PHASE 1** â€” this is foundation for everything else. Without working STDP other phases don't make sense.











PHASE 6: GENERATOR
LEGACY: This section is kept for reference. See PHASE 3.6 in the Authoritative Roadmap above.
- Motor cortex for sequential output
- Planning via target pattern activation
- Implementation via path search from pattern to words
- Syntax via myelinated structural patterns

========================================
ARCHITECTURAL DECISION
========================================

Chosen path: AUTONOMOUS MEMORY MODEL (without LLM)

Why:
- Fully matches philosophy (no weights, no optimization)
- Scaling is solvable (limit ~7000 connections per neuron, pruning)
- Pure brain model for research
- LLM can be added later as module if needed

Rejected options:
- Memory as LLM module â€” complication without clear benefit at this stage
- Memory as layer inside model â€” too complex (mixing gradients and Hebb)

========================================
CURRENT IMPLEMENTATION STATUS
========================================

IMPLEMENTED:

CORE:
- Neuron (neuron.py) â€” binary state, types EXCITATORY/INHIBITORY
- Connection (connection.py) â€” states NEW/USED/MYELINATED/PRUNE
  - ConnectionType: SEMANTIC (ventral) / SYNTACTIC (dorsal)
  - NO IS_A/HAS_PROPERTY â€” hierarchy is emergent
- Activation (activation.py) â€” spreading like "lightning"
- Pattern (pattern.py) â€” pattern as set of neurons and connections
- GraphStorage (graph_storage.py) â€” efficient storage (NumPy)

SEMANTIC MEMORY:
- Hebbian rule â€” connections created on co-activation
- STDP â€” connection directionality (forward_usage / backward_usage)
- Myelination â€” consolidation of frequent paths
- Chunking â€” grouping frequent sequences
- Inhibition â€” inhibitory neurons suppress weak branches
- Pruning â€” removal of unused connections

EMERGENT HIERARCHY:
- find_categories() â€” categories from graph topology (nodes with many incoming)
- get_related_concepts() â€” related concepts by connection strength
- NO explicit IS_A â€” categories arise from statistics

BIOLOGICAL ATTENTION:
- generate_with_attention() â€” generation with cumulative context
- spread_activation() â€” activation spreading to depth
- _spread_activation_weighted() â€” weighted spreading with hub penalty
- Decay â€” fading of old activations
- Hub penalty â€” hubs receive less activation (high threshold)
- Seed anchoring â€” topic always in memory
- Dead-end handling â€” search from active words
- Working memory â€” limited capacity (~7 items)

STATISTICS (curriculum + grade1 + FineWeb-Edu 1000 articles, 68K episodes) â€” verified 23.01.2026:
- Neurons: 48,301
- Connections: 1,453,469
- MYELINATED: 19,252 (1.3%)
- Episodes: 68,947 (NEW: 35,157, REPLAYED: 2,139, CONSOLIDATED: 30,748, DECAYING: 903)

TESTS (verified 23.01.2026):
- CURRICULUM: 49/50 (98%)
- PRESCHOOL: 46/48 (95.8%)
- GRADE1: 64/64 (100%)
- FineWeb-Edu: 7/9 (77.8%)
- bAbI Task 1: 250/250 (100%)
- TOTAL: 419/424 (98.8%)

IN PROGRESS:
- PHASE 3: API boundaries (Lexicon/InputLayer + OutputLayer) â€” foundation
- PHASE 3.6: Motor Output / Sequence Generator (word order)
- PHASE 3.7: Compositional WM reasoning (multi-hop)
- PHASE 4: Basal Ganglia (partial impl exists in basal_ganglia.py)
- LEGACY: PHASE 6: Generator â€” see PHASE 3.6

COMPLETED IN JANUARY 2026:
- PHASE 4: Attention and routing (PFC, MemoryRouter, AttentionGate)
- PHASE 5: Causality and reasoning (InferenceEngine, ThinkingEngine)
- PHASE 5.5: Working memory (temporary connections/episodes, recency bias)
- PHASE 5.6: Temporal Retrieval Refinement (is/was distinction, bAbI 100%)

========================================
GOAL
========================================

Model memory and knowledge formation as the brain does:
â€” without AI-style computations,
â€” without "weights" and optimizations,
â€” only through path/pattern search and selection based on their activation and consolidation of these patterns.

We search for paths/patterns and record them as patterns. Essentially this is similar to embeddings, but:
â€” embedding = only technical packaging of state/structure,
â€” forbidden to use it as geometric vector with distances and cosines.

Below clearly and in maximum detail: what is forbidden, what is allowed, and how to think about it.


========================================
1. GENERAL MODEL LOGIC
========================================

1.1. Memory = not "value", but PATTERN
- Pattern = set of neurons and connections that frequently activated together and became stable.
- We don't store "value" as a number.
- We store: "this path/ensemble â†’ pattern X".

1.2. Learning = not weight training, but path selection
- Frequently used paths are fixed (remain).
- Rarely used disappear.
- Stable patterns form themselves from repeating paths.

1.3. Activation = signal propagation
- Not database search.
- Not comparison with something.
- We simply launch "lightning" along existing connections and see where it stabilizes.


========================================
2. STRICTLY FORBIDDEN
========================================

(1) EXPLICIT NUMERIC WEIGHTS FORBIDDEN
- Cannot do connection.weight = 0.37, 0.85 etc. as "connection strength".
- Cannot update weights by formula (w += delta).
- Cannot think of "neuron-neuron" link as floating point number meaningful by itself.
- Connection exists or not. Maximum â€” qualitative states ("new / stable / dying"), but not continuous weight.

(2) METRICS AND DISTANCES FORBIDDEN
- Cannot use:
  - cosine similarity,
  - dot product,
  - Euclidean distance,
  - any "measureDistance(a,b)".
- Cannot select pattern by "minimum distance" or "maximum similarity" principle.
- No kNN, clustering, etc.

(3) OPTIMIZATIONS FORBIDDEN
- No:
  - gradient descent,
  - backpropagation,
  - minimization loss/error,
  - softmax probabilities.
- Cannot do:
  - "compute error â†’ adjust parameters".
- In the model there is no "error as number", only:
  - either pattern stabilized,
  - or collapsed.

(4) GLOBAL SEARCH ALGORITHMS FORBIDDEN
- Cannot use:
  - Dijkstra, A*,
  - BFS/DFS to find best path during "recall" or activation,
  - any global graph traversals for "optimal pattern search".
- Activation must spread locally:
  - neuron knows only its neighbors,
  - no global observer.

(5) PROBABILISTIC MODELS WITH MEANING FORBIDDEN
- No:
  - probability distributions as meaning carriers,
  - softmax(logits),
  - Bayesian updates.
- Randomness allowed only as chaos source (e.g., during connection formation), but not as "probabilistic knowledge model".

(6) FORBIDDEN TO THINK â€œLIKE DEEP LEARNING NETWORKSâ€
- No:
  - layers like Linear/ReLU/Transformer etc. as meaning carriers.
  - Can use techniques (arrays, lists, matrices) for storage, but:
  - these structures cannot be considered as abstract "neural network layers with trainable parameters".

(7) SYMBOLIC RULES FORBIDDEN
- Model should not work as logical engine:
  - "if A and B, then C" as code rule â€” cannot use this as memory mechanism.
- Logic/rules can only be in control code, but "memory" itself is not stored as if-rules.

(8) "EMBEDDING AS MEANING VECTOR" FORBIDDEN
- Cannot treat "embedding" as geometric object where:
  - embedding proximity = semantic proximity,
  - vector operations = semantic operations.
- Embedding allowed only as packaging:
  - "this object contains pattern structure",
  - nothing more.


========================================
3. WHAT IS ALLOWED (AND HOW TO THINK CORRECTLY)
========================================

(1) LOCAL CONNECTION HISTORY
- Simple, local principle allowed:
  - "this connection participated in activation many times â†’ consider it stable",
  - "barely participated â†’ consider it candidate for removal".
- This can be technically implemented as:
  - local event counter,
  - or flag accumulation.
- Important:
  - this counter cannot be used for global comparison,
  - it's not a "weight", but life/death criterion for connection.

(2) DISCRETE STATES INSTEAD OF NUMBERS
Example of allowed connection states:
- NEW (new, unstable),
- USED (used enough),
- MYELINATED (consolidated),
- PRUNE (for removal).

No floating-point ranges like [0.0 â€¦ 1.0] with interpretation "how strong the connection is".

(3) ACTIVATION AS LIGHTNING
- We simply launch activation:
  - neuron receives input â†’ either fires or not,
  - fired neuron signals neighbors.
- No "best next vertex" selection.
- Only local transmission.

(4) PATTERN AS SET OF NEURONS
- Pattern is described by:
  - set of neuron identifiers,
  - and/or connections between them.
- No "pattern = vector of length N".
- If internal format needed, can have:
  - Pattern = {id: ..., neurons: Set[NeuronId]}.

(5) MEMORY = LIST OF PATTERNS
- Can store as:
  - list (or graph) of already formed patterns.
- Recall:
  - input activation itself intersects with existing patterns,
  - we don't calculate "how similar", we simply see:
    - exactly this group of neurons activated â†’ means pattern restored.

(6) RANDOMNESS AS CHAOS, NOT "MODEL NOISE"
- Random can be used:
  - when creating initial connections,
  - when triggering spontaneous activity.
- Cannot:
  - use randomness as element of advanced probabilistic model (like "sample from meaning distribution").

(7) EMBEDDING AS PACKAGING
If absolutely need to represent pattern as object for logging/transfer:
- Embedding = structure serialization (e.g., list of neurons/connections, hash).
- Cannot:
  - use this embedding in cosines, attention matrices, etc.


========================================
4. ENTITIES OF THE MEMORY MODEL (HOW TO TRANSFER TO CODE)
========================================

(1) Neuron
- Has:
  - unique id,
  - list of incoming/outgoing connections,
  - state fired/not,
  - type: excitatory / inhibitory.
- Does not have numeric "activity weight".

(2) Connection
- Pair (from_neuron, to_neuron).
- States:
  - NEW / USED / MYELINATED / PRUNE.
- Local history:
  - how many times participated in successful activation (can use counter, but apply only locally: "has threshold been reached for transition NEWâ†’USEDâ†’MYELINATED").

(3) MyelinSheath
- Attribute of connection or path:
  - is_myelinated: True/False.
- Effect:
  - myelinated connection conducts first (e.g., updates earlier / not inhibited).
- No numeric "myelin levels".

(4) Pattern
- Described by:
  - set of neurons,
  - and/or set of connections.
- Condition: pattern formed if its neurons co-activated enough times and connections became MYELINATED/USED.

(5) Activation
- Process:
  - initial set of neurons activated (sensory input / internal trigger),
  - activation spreads along existing connections,
  - inhibitory neurons suppress excess.
- Result:
  - either network settles into stable pattern,
  - or activation collapses.

(6) Inhibition
- Inhibitory neurons:
  - receive input from active neurons,
  - suppress branches that conflict or are too weak.
- Important:
  - not through "scores",
  - but through "activation either exists or not".

(7) ExperienceEvent
- Any external/internal stimulus that:
  - triggers initial activation,
  - through repetition forms/strengthens pattern.

(8) Hippocampus (if modeling)
- Separate module:
  - temporarily stores new patterns (episodes),
  - on repeated activations helps transfer them to main cortex.
- Here too:
  - no weights,
  - simply stores set of temporary patterns and their usage.


========================================
5. ESSENCE OF MEMORY IN THE MODEL (SHORT FORMULA)
========================================

Memory in the model = not numbers, not vectors, not weights.

Memory = structure:
- which neurons are connected,
- which of these connections are alive and myelinated,
- which patterns are already stable,
- which patterns overlap.

Learning = structure change:
- appearance of new connections,
- disappearance of weak ones,
- transition of connections to "consolidated/myelinated" state,
- appearance and stabilization of new patterns,
- strengthening of pattern overlaps.

Activation = dynamics on this structure:
- launch signal,
- it goes along existing paths,
- physics itself (local rules) determines which pattern survives.

No global calculations.
No optimizations.
Only path/pattern search and selection based on their activation and repetition.

========================================
6. ADDITION: WHAT IS "PATH SEARCH" IN THIS MODEL (NOT AN ALGORITHM)
========================================

Important to clearly define:  
"path search" here is NOT an algorithm.  
It is NOT graph search.  
NOT choosing best option.  
NOT scanning the network.

6.1. PATH SEARCH = NATURAL ACTIVATION SPREADING
When we say "path search", we mean:
- give initial activation to several neurons,
- allow activation to spread through existing connections,
- inhibition removes weak,
- myelinated paths conduct faster,
- network itself settles into stable configuration (pattern).

This is the same as:
throwing a ball on terrain â€” it will find the deepest valley itself.

6.2. PATH SEARCH CANNOT BE:
- iteration over all connections,
- distance calculation,
- "best next vertex" selection,
- comparison of options.

Activation goes PARALLEL AND LOCAL:
each neuron knows only its neighbors and its status.

6.3. PATH SEARCH RESULT:
- if signal stabilized â†’ pattern found,
- if collapsed â†’ nothing found.

This is natural dynamics.  
No computations.


========================================
7. ADDITION: WHAT IS "PATTERN" IN OUR MODEL (SUPER-CLEAR)
========================================

Pattern consists of three levels:

7.1. STRUCTURAL LEVEL
- Set of neurons connected by stable (myelinated or stable) paths.

7.2. DYNAMIC LEVEL
- These neurons can synchronously activate and support each other.

7.3. HISTORICAL LEVEL
- These connections were traversed by activation many times.
- Pattern is preceded by repeated experience.

Pattern = structural + dynamic + historical unit of knowledge.

Pattern DOES NOT have:
- center,
- number,
- weight,
- coordinates,
- symbol.

It exists as network configuration.

7.4. PATTERN OVERLAP
If two groups of neurons frequently activated together:
- part of connections/neurons becomes shared,
- new stable overlap arises,
- category/meaning appears.

Example:
pattern "table" and pattern "chair" â†’ shared overlap â†’ "furniture".

This is the basis of semantics.


========================================
8. ADDITION: HOW INHIBITION WORKS (KEY MECHANISM)
========================================

Inhibition is not calculated, not computed.
It acts locally and automatically.

8.1. When neuron activates â†’ it excites its inhibitory neighbors.
8.2. Inhibitory neurons suppress:
- all branches that diverge,
- all weak and inconsistent activations.

8.3. Effect:
- competing paths are extinguished,
- only single stable pattern remains.

This is natural elimination of errors and noise.

In code inhibition means:
- excitation of "inhibitory" type cell â†’ blocking activation transmission through its target connections.


========================================
9. ADDITION: HOW MYELIN WORKS IN THE MODEL
========================================

In nature myelin:
- increases signal conduction speed,
- reduces losses,
- gives path priority over others.

In the model:

PATH IS CONSIDERED MYELINATED IF:
- it participated in stable activation enough times.

WHAT MYELIN PROVIDES:
- activation passes through this connection first,
- inhibition barely suppresses it,
- it dominates over non-myelinated branches,
- such paths form patterns.

Important:
- myelin = boolean flag, NOT a number.


========================================
10. ADDITION: HOW MEMORY IS FORMED
========================================

10.1. Input triggers activation.
10.2. Activation spreads through network.
10.3. If configuration repeated before:
- stabilizes â†’ pattern recalled.

10.4. If configuration is new:
- it's unstable until repetition occurs.

10.5. Repetition â†’ strengthening â†’ myelin â†’ pattern.

10.6. Patterns merge, overlap â†’ categories and meanings appear.

This strictly corresponds to nature.


========================================
11. ADDITION: HOW TO TRANSFER ALL THIS TO CODE (GENERAL SCHEME)
========================================

11.1. CREATE CLASSES:
- Neuron
- Connection
- Pattern
- Activation
- Inhibition
- ExperienceEvent
- Cortex (top-level pattern logic)
- Hippocampus (temporary buffer)

11.2. DO NOT CREATE:
- weights,
- similarity matrices,
- distances,
- optimization functions,
- embeddings as distances,
- graph searches.

11.3. ACTIVATION:
- list of currently active neurons,
- list of new neurons activated through connections,
- inhibition removes bad branches,
- repetition â†’ consolidation â†’ pattern.

11.4. MEMORY STORAGE:
- list of patterns,
- each pattern â€” set of neurons,
- pattern overlaps â†’ meaning.

11.5. LET NATURE DO THE WORK:
- don't calculate,
- don't optimize,
- just let network stabilize itself.


========================================
12. SHORTEST SUMMARY OF THE ENTIRE MODEL
========================================

Memory = stabilized paths (patterns).

Patterns arise:
- from chaos,
- through repetition,
- through myelin,
- through inhibition,
- through overlap.

Brain doesn't calculate.  
Brain doesn't compare.  
Brain doesn't optimize.

It simply passes activation through structure,  
and this structure rewrites itself with experience.

TASK IN CODE:
model structure + dynamics,  
not mathematics.

========================================
13. COMPLETE MODEL WORKFLOW (STEP BY STEP)
========================================

Here is the complete "pipeline" â€” what will actually happen in the system,
from receiving experience to memory and meaning emergence.

NO STEP USES CALCULATIONS, WEIGHTS OR OPTIMIZATIONS.


----------------------------------------
STEP 1. RAW NETWORK IS FORMED
----------------------------------------

1.1. Neurons are created:
- excitatory,
- inhibitory.

1.2. Chaotic connections (Connection) form between them:
- random,
- unordered,
- many excess.

1.3. No connection has weight â€” only status:
- NEW (just appeared),
- USED (used multiple times),
- MYELINATED (consolidated forever),
- PRUNE (for removal).

This is start "like a child": chaos, excess, no optimization.


----------------------------------------
STEP 2. EXPERIENCE ARRIVES (SENSOR/INTERNAL INPUT)
----------------------------------------

2.1. ExperienceEvent arrives:
- vision,
- sound,
- touch,
- idea,
- internal signal.

2.2. Some neurons activate first (activation start).


----------------------------------------
STEP 3. ACTIVATION SPREADS (LIKE LIGHTNING)
----------------------------------------

3.1. Active neuron excites only direct neighbors.
3.2. No searches, no comparisons â€” only local transitions.
3.3. Activation goes through connections:
- MYELINATED â†’ pass first,
- USED â†’ pass normally,
- NEW â†’ pass weaker,
- PRUNE â†’ don't pass.

3.4. If activation collapses (insufficient connections) â†’ experience not consolidated.


----------------------------------------
STEP 4. INHIBITION CLEARS NOISE
----------------------------------------

4.1. Inhibitory neurons, when excited, block:
- weak branches,
- random paths,
- inconsistent micro-activations.

4.2. Only single "living" activation branch remains.

This is auto-correction without computations.


----------------------------------------
STEP 5. IF ACTIVATION BECAME STABLE â†’ PATTERN FORMS
----------------------------------------

5.1. If several neurons stably activate together:
- connections between them transition to USED.

5.2. If this experience repeats:
- connections get myelin â†’ become MYELINATED.

5.3. Group of neurons + stabilized connections = PATTERN.

Pattern = structure + dynamics + history.
No numbers.


----------------------------------------
STEP 6. CONSOLIDATION THROUGH REPETITION
----------------------------------------

6.1. Single event by itself doesn't create memory.
6.2. Only repeated activations along same paths:
- remove excess,
- strengthen needed.

6.3. Myelin makes path dominant forever.


----------------------------------------
STEP 7. PATTERN OVERLAP â†’ MEANING EMERGENCE
----------------------------------------

7.1. If two patterns activate frequently together:
- some neurons participate in both,
- some connections are shared.

7.2. Shared overlap appears â€” new structure.

7.3. This is category/meaning.

Examples:
- face + voice â†’ "person"
- table + chair + cabinet â†’ "furniture"
- hand + vision of hand â†’ "mine"

No calculations.
Meaning = physical intersection.


----------------------------------------
STEP 8. RECALL = PATTERN RE-ACTIVATION
----------------------------------------

8.1. New input activates part of pattern.
8.2. Remaining pattern neurons automatically "pull up".
8.3. Inhibition removes everything else.

Result: pattern restored.

This is recall.


----------------------------------------
STEP 9. HIPPOCAMPUS ROLE (OPTIONAL MODEL)
----------------------------------------

Real mechanism:

9.1. Hippocampus catches "new episodes".
9.2. Forms temporary pattern (fast, without myelin).
9.3. Through repetition transfers it to neocortex.
9.4. Neocortex makes pattern permanent (through myelin).

In the model:
- can implement as separate temporary patterns module.


----------------------------------------
STEP 10. OLD PATHS WIN
----------------------------------------

10.1. In adults, myelin almost stops forming.
10.2. Old paths are fast â†’ activated first.
10.3. New paths are weak â†’ without repetition, inhibition suppresses them.
10.4. Therefore, multiple repetition is required â†’ to make a new path stable.


========================================
14. PRACTICAL SCHEME FOR TRANSFER TO IDE
========================================

Described so you can immediately start writing code.


----------------------------------------
14.1. CLASSES
----------------------------------------

class Neuron:
    id
    type: excitatory / inhibitory
    connections_out: list[Connection]
    connections_in: list[Connection]
    active: bool

class Connection:
    from_neuron
    to_neuron
    state: NEW / USED / MYELINATED / PRUNE
    usage_count: int  # allowed, but only as local life/death criterion
    is_myelinated: bool

class Pattern:
    neurons: set[Neuron]
    connections: set[Connection]
    # pattern = structure

class Activation:
    active_neurons: set[Neuron]

class Cortex:
    patterns: list[Pattern]

class Hippocampus:
    temporary_patterns: list[Pattern]

class ExperienceEvent:
    triggered_neurons: set[Neuron]


----------------------------------------
14.2. ACTIVATION PROCESS (NOT ALGORITHM, BUT DYNAMICS)
----------------------------------------

process_experience(event):
    activation = event.triggered_neurons

    while activation not empty:
        next_activation = empty

        for neuron in activation:
            for conn in neuron.connections_out:
                if connection PRUNE â†’ skip
                if connection myelinated â†’ activate to_neuron FIRST
                if connection USED â†’ activate normally
                if connection NEW â†’ can activate, but weaker (may be suppressed by inhibition)

                if to_neuron not yet active:
                    next_activation.add(to_neuron)

        apply inhibition to next_activation  
            (remove inconsistent/weak)

        activation = next_activation

    # if network stabilized into pattern â†’ update connections (NEWâ†’USED, USEDâ†’MYELINATED)


----------------------------------------
14.3. CONNECTION UPDATE
----------------------------------------

update_connections(pattern):
    for each connection in pattern:
        if state == NEW:
            state = USED
        if state == USED AND connection participated multiple times:
            state = MYELINATED

----------------------------------------
14.4. PATTERN FORMATION
----------------------------------------

form pattern if:
- group of neurons co-activated,
- connections within this group transitioned to USED or MYELINATED.

----------------------------------------
14.5. MEMORY STORAGE
----------------------------------------

cortex.patterns.append(pattern)


========================================
15. FINAL MAXI-REFERENCE TO THE THOUGHT
========================================

Memory model IS NOT:
- mathematics,
- weights,
- optimization,
- distances,
- logic.

Memory model IS:
- huge network,
- activation lightning,
- natural path selection,
- myelin,
- stable patterns,
- pattern overlaps â†’ meanings.

Transfer to code:
- not as "neural network model",
- but as "self-organizing structure model".

You are ready for implementation: you now have complete specification without gaps.

========================================
16. HOW NEW MEMORIES APPEAR (CREATION MECHANICS)
========================================

Condition 1 â€” new experience arrived.
Condition 2 â€” it doesn't match existing pattern.
Condition 3 â€” part of activation still stabilizes (even if weakly).

Mechanics:

16.1. New input triggers activation.
16.2. Signal goes along NON-myelinated paths â†’ unstable activity.
16.3. Small "island" of stable activation is found.
16.4. These connections get USED status.
16.5. If experience repeats â†’ they become MYELINATED.
16.6. If experience is unique â†’ weak pattern without myelin remains â†’ easily forgotten.

No numbers, only connection statuses and presence/absence of repetition.


========================================
17. HOW OLD MEMORIES ARE UPDATED
========================================

17.1. Old patterns are already myelinated.
17.2. New experience, similar to old, activates part of old pattern.
17.3. Remaining pattern neurons are pulled up automatically.
17.4. New connections are added (NEW â†’ USED) that didn't participate before.
17.5. If these new connections repeat â†’ they also become MYELINATED.

This is how memory is updated naturally:
Old + new elements â†’ expanded pattern.


========================================
18. HOW FORGETTING HAPPENS
========================================

Forgetting â€” NOT erasure and NOT "weight" reduction.
Forgetting = structural death.

18.1. Connection unused for long â†’ its status = PRUNE.
18.2. PRUNE structures are removed.
18.3. Patterns that lost part of connections collapse.
18.4. Only patterns that continue participating in experience remain.

Forgetting = disappearance of unused paths.


========================================
19. HOW PATTERNS INTERACT (STRICTLY)
========================================

19.1. If two patterns activate together â†’ their neurons start overlapping.
19.2. The more often they activate together â†’ the more overlap.
19.3. Overlap creates category/generalization.
19.4. Category becomes new higher-level pattern.

Example:
table â†” chair â†” cabinet â†’ joint activity â†’ "furniture".


========================================
20. HOW DIFFERENT SENSES WORK IN ONE MODEL
========================================

Key here:  
Vision, hearing, skin, smell â€” ALL united by one mechanism.

20.1. Each sense has its own "input layer" of neurons.
20.2. Inputs go to different cortex areas (V1, A1, S1â€¦).
20.3. Overlaps form in associative areas:
- MT â€” movement,
- STS â€” face+voice,
- parietal cortex â€” body+vision,
- prefrontal â€” meaning+context.

20.4. Patterns from different modalities glue together through joint activation.

Example:
see dog + hear bark â†’ shared pattern (multisensory).


========================================
21. HOW ABSTRACTIONS FORM
========================================

Abstraction = overlap of overlaps.

21.1. Many similar patterns â†’ shared pattern.
21.2. Many shared patterns â†’ even more shared pattern.

Example:
table, chair, cabinet â†’ furniture  
furniture, walls, windows â†’ interior  
interior, street â†’ space  
and so on.

Abstractions â€” not level "above", but level "deeper into overlap center".


========================================
22. HOW MODEL PREVENTS CONFLICTS
========================================

22.1. If two paths activate simultaneously and conflict:
- inhibition extinguishes weak path.

22.2. If conflict not resolved â€” activation collapses and pattern NOT formed.

22.3. Patterns with myelin always win.

This controls memory stability.


========================================
23. HOW THE NETWORK SELF-LIMITS
========================================

23.1. No infinite growth.
23.2. If pattern not repeated â€” PRUNE.
23.3. New connections appear only with new flashes.
23.4. Old connections disappear without support.

This maintains balance and prevents degradation.


========================================
24. HOW ATTENTION WORKS
========================================

Attention â€” NOT a number, not weight, not coefficient.  
It's a set of physical mechanisms:

24.1. Thalamus passes only certain type signals.
24.2. Prefrontal cortex activates pattern that should dominate.
24.3. Inhibition suppresses all alternative paths.

Attention = highlighting needed pattern through its dominance.


========================================
25. HOW CONTEXT WORKS
========================================

25.1. Context â€” active patterns already "burning" in network.
25.2. New input overlays on current pattern â†’ new combination forms.
25.3. Current pattern can direct activation along needed paths.
25.4. Patterns matching context activate easier.

Context = background patterns.


========================================
26. HOW INPUT PRIORITY WORKS
========================================

26.1. Myelinated paths â†’ highest speed.
26.2. Frequently used paths â†’ high probability of becoming active.
26.3. New paths â†’ low chance.
26.4. Inhibition â†’ kills weak ones.

Priority = physical property, NOT computation.


========================================
27. "ERROR â†’ ROLLBACK" MECHANISM
========================================

27.1. If activation goes along path NOT connected to stable network:
- inhibition extinguishes path,
- activity collapses.

27.2. Rollback process â€” automatic:
- no support â†’ path doesn't live.

27.3. Brain does NOT store error, it simply doesn't consolidate it.


========================================
28. BOUNDARY FROM ANY NEURAL NETWORKS AND AI
========================================

OUR MODEL IS NOT:
- neural network,
- perceptron,
- RNN,
- transformer,
- autoencoder,
- trainable matrix,
- weight model,
- probabilistic model.

OUR MODEL IS:
- dynamic structure of nodes,
- which develops structurally on its own,
- where repetition forms paths,
- myelin strengthens paths,
- inhibition extinguishes noise,
- patterns overlap,
- memory = structure, not computation.


========================================
29. FINAL BLOCK â€” ENTIRE MODEL IN ONE PHRASE
========================================

Memory = not numbers and not algorithms.  
Memory = structure of paths that:
- appeared from chaos,
- consolidated through repetition,
- strengthened by myelin,
- stabilized by inhibition,
- organized into patterns,
- patterns overlapped,
- overlaps became meanings.

This is exactly like in the brain.


========================================
30. READY FOR IMPLEMENTATION
========================================

Now the model is complete:
- no logical gaps,
- all your requirements met,
- all types of computations excluded,
- all natural mechanisms included,
- classes exist,
- dynamics exist,
- learning rules exist,
- forgetting rules exist,
- meaning mechanism exists,
- pattern interaction exists,
- model of different brain zones exists,
- attention, context, priority exist.

Can transfer to IDE and start implementation.
